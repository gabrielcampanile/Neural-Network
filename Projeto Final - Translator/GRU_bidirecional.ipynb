{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gabrielcampanile/Neural-Network/blob/main/Projeto%20Final%20-%20Translator/GRU_bidirecional.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tradutor Inglês-Português com Redes Sequência-a-Sequência, Atenção e GRU Bidirecional\n",
        "\n",
        "Este notebook implementa um modelo de tradução automática de inglês para português, baseado no tutorial \"NLP From Scratch: Translation with a Sequence to Sequence Network and Attention\" do PyTorch, com aprimoramento para usar redes GRU bidirecionais.\n",
        "\n",
        "A arquitetura utilizada é um modelo **Sequence-to-Sequence (Seq2Seq)** composto por um **Encoder** e um **Decoder** com redes neurais recorrentes (**GRU Bidirecional** no Encoder). Para melhorar a performance, implementamos um **Mecanismo de Atenção (Attention)**, que permite ao modelo focar em partes específicas da frase de entrada ao gerar a tradução.\n",
        "\n",
        "**Estratégia Principal:** Para garantir que o treinamento seja computacionalmente viável e rápido, seguimos a orientação de limitar o tamanho do nosso dataset. Em vez de usar todas as frases disponíveis, criamos um vocabulário com as palavras mais frequentes e filtramos o dataset para usar apenas um número limitado de frases que podem ser formadas com esse vocabulário.\n",
        "\n",
        "----\n"
      ],
      "metadata": {
        "id": "NTnVUPlcVUr5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Para plotagem no notebook\n",
        "%matplotlib inline\n",
        "\n",
        "# Imports principais\n",
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import re\n",
        "import random\n",
        "import time\n",
        "import math\n",
        "\n",
        "# Imports do PyTorch e utilidades\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
        "\n",
        "# Imports para plotagem\n",
        "import matplotlib.pyplot as plt\n",
        "#plt.switch_backend('agg')\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "# Configuração do dispositivo (GPU ou CPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Usando dispositivo: {device}\")\n",
        "\n",
        "# Tokens especiais para marcar início e fim de sentenças\n",
        "SOS_token = 0\n",
        "EOS_token = 1\n"
      ],
      "metadata": {
        "id": "P36Ivcu6Vg1i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1ebbd3f-70ff-4fa9-c81c-a7d415bcc81e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Usando dispositivo: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparação dos Dados: Classes e Funções de Normalização\n",
        "\n",
        "Para trabalhar com texto, primeiro precisamos processá-lo.\n",
        "\n",
        "1.  **Classe `Lang`**: Uma classe auxiliar para criar um vocabulário. Ela mapeia cada palavra única para um índice numérico (e vice-versa) e conta a frequência de cada palavra.\n",
        "2.  **Normalização de Strings**: Funções para converter o texto para um formato padrão: minúsculas, remoção de acentos e de caracteres especiais. Isso reduz a complexidade do vocabulário.\n",
        "\n",
        "-----"
      ],
      "metadata": {
        "id": "asfIFZQ2VpHr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokens especiais atualizados\n",
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "UNK_token = 2 # Novo token para palavras desconhecidas\n",
        "\n",
        "# Classe Lang atualizada para incluir UNK\n",
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\", 2: \"<UNK>\"}\n",
        "        self.n_words = 3\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1\n",
        "\n",
        "# Converte uma string Unicode para ASCII puro\n",
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "    )\n",
        "\n",
        "# Deixa em minúsculo, remove espaços e caracteres não-letra\n",
        "def normalizeString(s):\n",
        "    s = unicodeToAscii(s.lower().strip())\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
        "    s = re.sub(r'\\s+', ' ', s).strip()\n",
        "    return s"
      ],
      "metadata": {
        "id": "En4yDZRMVvWU"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Leitura e Filtragem de Dados\n",
        "\n",
        "Aqui definimos as funções para carregar, processar e preparar o dataset para o treinamento. Esta é a etapa mais customizada do nosso projeto.\n",
        "\n",
        "1.  `readLangs`: Lê o arquivo de texto `eng-por.txt` e o divide em pares de sentenças.\n",
        "2.  `prepareDataWithVocabLimit`: Nossa função principal de preparação. Ela lê todos os pares, conta a frequência das palavras, cria vocabulários com as `N` palavras mais comuns, e então filtra o dataset para manter apenas um número limitado de frases curtas que usam exclusivamente palavras desses vocabulários.\n",
        "3.  `get_dataloader`: Junta tudo, executa a preparação e cria um `DataLoader` do PyTorch, que nos ajudará a alimentar o modelo com dados em lotes (batches) de forma eficiente.\n",
        "\n",
        "-----"
      ],
      "metadata": {
        "id": "568AYrZ_V8VX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def readLangs(lang1, lang2, reverse=False):\n",
        "    print(\"Lendo as linhas...\")\n",
        "    # Assumimos que o arquivo limpo está em 'data/eng-por.txt'\n",
        "    lines = open(f'data/{lang1}-{lang2}.txt', encoding='utf-8').read().strip().split('\\n')\n",
        "\n",
        "    pairs = []\n",
        "    for l in lines:\n",
        "      line_parts = l.split('\\t')\n",
        "      if len(line_parts) == 2:\n",
        "        pairs.append([normalizeString(s) for s in line_parts])\n",
        "\n",
        "    if reverse:\n",
        "        pairs = [list(reversed(p)) for p in pairs]\n",
        "        input_lang = Lang(lang2)\n",
        "        output_lang = Lang(lang1)\n",
        "    else:\n",
        "        input_lang = Lang(lang1)\n",
        "        output_lang = Lang(lang2)\n",
        "\n",
        "    return input_lang, output_lang, pairs\n",
        "\n",
        "def prepareDataWithVocabLimit(lang1, lang2, reverse=False, max_vocab_size=4000, max_pairs=None):\n",
        "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
        "    print(f\"Lidos {len(pairs)} pares de sentenças\")\n",
        "\n",
        "    temp_input_lang = Lang(input_lang.name)\n",
        "    temp_output_lang = Lang(output_lang.name)\n",
        "    for pair in pairs:\n",
        "        temp_input_lang.addSentence(pair[0])\n",
        "        temp_output_lang.addSentence(pair[1])\n",
        "    print(\"Contagem de palavras completa.\")\n",
        "\n",
        "    sorted_input_vocab = sorted(temp_input_lang.word2count.items(), key=lambda item: item[1], reverse=True)\n",
        "    sorted_output_vocab = sorted(temp_output_lang.word2count.items(), key=lambda item: item[1], reverse=True)\n",
        "\n",
        "    input_lang = Lang(input_lang.name)\n",
        "    output_lang = Lang(output_lang.name)\n",
        "    for word, _ in sorted_input_vocab[:max_vocab_size-2]:\n",
        "        input_lang.addWord(word)\n",
        "    for word, _ in sorted_output_vocab[:max_vocab_size-2]:\n",
        "        output_lang.addWord(word)\n",
        "    print(f\"Vocabulário limitado criado. Input: {input_lang.n_words} palavras, Output: {output_lang.n_words} palavras.\")\n",
        "\n",
        "    filtered_pairs = []\n",
        "    for pair in pairs:\n",
        "        if len(pair[0].split(' ')) >= MAX_LENGTH or len(pair[1].split(' ')) >= MAX_LENGTH:\n",
        "            continue\n",
        "        input_valid = all(word in input_lang.word2index for word in pair[0].split(' '))\n",
        "        output_valid = all(word in output_lang.word2index for word in pair[1].split(' '))\n",
        "        if input_valid and output_valid:\n",
        "            filtered_pairs.append(pair)\n",
        "\n",
        "    if max_pairs:\n",
        "        random.shuffle(filtered_pairs)\n",
        "        filtered_pairs = filtered_pairs[:max_pairs]\n",
        "\n",
        "    print(f\"Dataset final com {len(filtered_pairs)} pares de sentenças.\")\n",
        "    return input_lang, output_lang, filtered_pairs\n",
        "\n",
        "def get_dataloader(batch_size, lang1, lang2, device, max_vocab_size=4000, max_pairs=None, reverse=True):\n",
        "    input_lang, output_lang, pairs = prepareDataWithVocabLimit(lang1, lang2, reverse, max_vocab_size, max_pairs)\n",
        "    n = len(pairs)\n",
        "    input_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n",
        "    target_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n",
        "\n",
        "    for idx, (inp, tgt) in enumerate(pairs):\n",
        "        inp_ids = [input_lang.word2index[word] for word in inp.split(' ')]\n",
        "        tgt_ids = [output_lang.word2index[word] for word in tgt.split(' ')]\n",
        "        inp_ids.append(EOS_token)\n",
        "        tgt_ids.append(EOS_token)\n",
        "        input_ids[idx, :len(inp_ids)] = inp_ids\n",
        "        target_ids[idx, :len(tgt_ids)] = tgt_ids\n",
        "\n",
        "    train_data = TensorDataset(torch.LongTensor(input_ids).to(device),\n",
        "                               torch.LongTensor(target_ids).to(device))\n",
        "    train_sampler = RandomSampler(train_data)\n",
        "    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "    return input_lang, output_lang, train_dataloader, pairs"
      ],
      "metadata": {
        "id": "lpwQtCN9WBNt"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A Arquitetura do Modelo: Seq2Seq com Atenção e GRU Bidirecional\n",
        "\n",
        "#### Encoder\n",
        "\n",
        "O `EncoderRNN` processa a frase de entrada e a comprime em um vetor de contexto. Ele usa uma camada de *Embedding* para transformar os índices das palavras em vetores densos, e uma camada **GRU Bidirecional** para processar a sequência em ambas as direções (da esquerda para a direita e da direita para a esquerda). Isso permite que o encoder capture dependências de longo alcance e tenha uma representação mais rica do contexto da frase de entrada.\n",
        "\n",
        "#### Attention Decoder\n",
        "\n",
        "O `AttnDecoderRNN` gera a frase de saída. A cada passo, ele usa o mecanismo `BahdanauAttention` para calcular pesos de atenção, criando um vetor de contexto ponderado que foca nas partes mais relevantes da entrada. Este contexto (agora derivado das saídas bidirecionais do encoder) é combinado com a palavra anterior para prever a próxima palavra da tradução.\n",
        "\n",
        "-----"
      ],
      "metadata": {
        "id": "OmrLACVrWHnN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, dropout_p=0.1):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "\n",
        "        # A MUDANÇA PRINCIPAL ESTÁ AQUI: adicionamos bidirectional=True\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True, bidirectional=True)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "\n",
        "    def forward(self, input):\n",
        "        # A lógica do forward continua a mesma\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        output, hidden = self.gru(embedded)\n",
        "        return output, hidden\n",
        "\n",
        "class BahdanauAttention(nn.Module):\n",
        "    def __init__(self, hidden_size):\n",
        "        super(BahdanauAttention, self).__init__()\n",
        "        self.Wa = nn.Linear(hidden_size, hidden_size)\n",
        "        # MUDANÇA: Ua agora recebe a saída do encoder bidirecional (hidden_size * 2)\n",
        "        self.Ua = nn.Linear(hidden_size * 2, hidden_size)\n",
        "        self.Va = nn.Linear(hidden_size, 1)\n",
        "\n",
        "    def forward(self, query, keys):\n",
        "        # A lógica do forward continua a mesma\n",
        "        scores = self.Va(torch.tanh(self.Wa(query) + self.Ua(keys)))\n",
        "        scores = scores.squeeze(2).unsqueeze(1)\n",
        "        weights = F.softmax(scores, dim=-1)\n",
        "        # O 'context' agora terá hidden_size * 2, pois é um produto de 'weights' e 'keys'\n",
        "        context = torch.bmm(weights, keys)\n",
        "        return context, weights\n",
        "\n",
        "class AttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, dropout_p=0.1):\n",
        "        super(AttnDecoderRNN, self).__init__()\n",
        "\n",
        "        # O tamanho do embedding é o mesmo\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "\n",
        "        # A classe de Atenção já foi ajustada, aqui apenas a instanciamos\n",
        "        self.attention = BahdanauAttention(hidden_size)\n",
        "\n",
        "        # MUDANÇA: Camada para combinar os hidden states do encoder (frente e trás)\n",
        "        self.fc_hidden = nn.Linear(hidden_size * 2, hidden_size)\n",
        "\n",
        "        # MUDANÇA: A entrada da GRU agora é o embedding + o contexto da atenção (hidden_size * 2)\n",
        "        self.gru = nn.GRU(hidden_size + (hidden_size * 2), hidden_size, batch_first=True)\n",
        "\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "\n",
        "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
        "        batch_size = encoder_outputs.size(0)\n",
        "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token)\n",
        "\n",
        "        # MUDANÇA: Combinar os estados ocultos do encoder\n",
        "        # O encoder_hidden tem shape (2, batch_size, hidden_size)\n",
        "        # Concatenamos ao longo da dimensão da feature para obter (1, batch_size, hidden_size * 2)\n",
        "        encoder_hidden_concat = torch.cat((encoder_hidden[0:1], encoder_hidden[1:2]), dim=2)\n",
        "        # Passamos pela camada linear para obter o shape esperado pelo decoder (1, batch_size, hidden_size)\n",
        "        decoder_hidden = torch.tanh(self.fc_hidden(encoder_hidden_concat))\n",
        "\n",
        "        decoder_outputs = []\n",
        "        attentions = []\n",
        "\n",
        "        for i in range(MAX_LENGTH):\n",
        "            decoder_output, decoder_hidden, attn_weights = self.forward_step(\n",
        "                decoder_input, decoder_hidden, encoder_outputs\n",
        "            )\n",
        "            decoder_outputs.append(decoder_output)\n",
        "            attentions.append(attn_weights)\n",
        "\n",
        "            if target_tensor is not None:\n",
        "                decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing\n",
        "            else:\n",
        "                _, topi = decoder_output.topk(1)\n",
        "                decoder_input = topi.squeeze(-1).detach()\n",
        "\n",
        "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
        "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
        "        attentions = torch.cat(attentions, dim=1)\n",
        "\n",
        "        return decoder_outputs, decoder_hidden, attentions\n",
        "\n",
        "    def forward_step(self, input, hidden, encoder_outputs):\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "\n",
        "        query = hidden.permute(1, 0, 2)\n",
        "        # O context retornado pela atenção agora tem hidden_size * 2\n",
        "        context, attn_weights = self.attention(query, encoder_outputs)\n",
        "\n",
        "        # MUDANÇA: A concatenação agora usa o 'context' maior\n",
        "        input_gru = torch.cat((embedded, context), dim=2)\n",
        "\n",
        "        output, hidden = self.gru(input_gru, hidden)\n",
        "        output = self.out(output)\n",
        "\n",
        "        return output, hidden, attn_weights"
      ],
      "metadata": {
        "id": "tD_bvlMPWUD-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Treinamento do Modelo\n",
        "\n",
        "Definimos agora as funções para treinar nosso modelo.\n",
        "\n",
        "  - `train_epoch`: Executa uma única época de treinamento. Para cada lote de dados, ela passa as frases pelo encoder e decoder, calcula a perda (o quão errada a previsão foi) e atualiza os pesos das redes usando os otimizadores.\n",
        "  - `train`: Orquestra o processo de treinamento completo por várias épocas, chamando `train_epoch` repetidamente. Ela também monitora a perda, exibe o progresso e o tempo decorrido.\n",
        "  - `asMinutes` e `timeSince`: Funções auxiliares para formatar o tempo de treinamento.\n",
        "\n",
        "-----"
      ],
      "metadata": {
        "id": "lcGV-iU4WX10"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
      ],
      "metadata": {
        "id": "0os6Zie9WaMu"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion):\n",
        "    total_loss = 0\n",
        "    for data in dataloader:\n",
        "        input_tensor, target_tensor = data\n",
        "\n",
        "        encoder_optimizer.zero_grad()\n",
        "        decoder_optimizer.zero_grad()\n",
        "\n",
        "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
        "        decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden, target_tensor)\n",
        "\n",
        "        loss = criterion(\n",
        "            decoder_outputs.view(-1, decoder_outputs.size(-1)),\n",
        "            target_tensor.view(-1)\n",
        "        )\n",
        "        loss.backward()\n",
        "\n",
        "        encoder_optimizer.step()\n",
        "        decoder_optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(dataloader)\n",
        "\n",
        "def train(train_dataloader, encoder, decoder, n_epochs, learning_rate=0.001, print_every=100, plot_every=100):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0\n",
        "    plot_loss_total = 0\n",
        "\n",
        "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        loss = train_epoch(train_dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if epoch % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print(\"=\" * 50)\n",
        "            print(f\"⏳ Tempo decorrido: {timeSince(start, epoch / n_epochs)}\")\n",
        "            print(f\"📅 Época: {epoch}/{n_epochs} ({epoch / n_epochs * 100:.2f}%)\")\n",
        "            print(f\"📉 Loss médio: {print_loss_avg:.4f}\")\n",
        "            print(\"=\" * 50 + \"\\n\")\n",
        "\n",
        "        if epoch % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "\n",
        "    showPlot(plot_losses)"
      ],
      "metadata": {
        "id": "hELx7ooxW01V"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plotando os Resultados\n",
        "\n",
        "Uma função simples para plotar a perda (loss) ao longo do treinamento. Ver a perda diminuir é um bom sinal de que o modelo está aprendendo.\n",
        "\n",
        "-----"
      ],
      "metadata": {
        "id": "dua2iVhuW9jx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def showPlot(points):\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots()\n",
        "    loc = ticker.MultipleLocator(base=0.2)\n",
        "    ax.yaxis.set_major_locator(loc)\n",
        "    plt.plot(points)\n",
        "    plt.xlabel(\"Épocas (x100)\")\n",
        "    plt.ylabel(\"Perda (Loss)\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "U9jmJf_tW-QE"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Avaliação e Visualização\n",
        "\n",
        "Após o treinamento, precisamos de funções para testar nosso modelo.\n",
        "\n",
        "  - `evaluate`: Recebe uma frase em português, a traduz para o inglês e retorna a tradução.\n",
        "  - `evaluateRandomly`: Pega `n` frases aleatórias do nosso dataset de teste, exibe a entrada, o alvo (tradução correta) e a saída do modelo (tradução prevista). É ótima para uma avaliação qualitativa rápida.\n",
        "\n",
        "-----"
      ],
      "metadata": {
        "id": "zwNv9jS4XC1X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(encoder, decoder, sentence, input_lang, output_lang):\n",
        "    with torch.no_grad():\n",
        "        # Converte a sentença de entrada em um tensor de índices.\n",
        "        # Se uma palavra não for encontrada, usa o UNK_token.\n",
        "        input_indices = [input_lang.word2index.get(word, UNK_token) for word in sentence.split(' ')]\n",
        "        input_indices.append(EOS_token)\n",
        "        input_tensor = torch.tensor(input_indices, dtype=torch.long, device=device).view(1, -1)\n",
        "\n",
        "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
        "        decoder_outputs, decoder_hidden, decoder_attn = decoder(encoder_outputs, encoder_hidden)\n",
        "\n",
        "        _, topi = decoder_outputs.topk(1)\n",
        "        decoded_ids = topi.squeeze()\n",
        "\n",
        "        decoded_words = []\n",
        "        for idx in decoded_ids:\n",
        "            if idx.item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            # O output não precisa de UNK, pois ele sempre gera palavras de seu vocabulário\n",
        "            decoded_words.append(output_lang.index2word[idx.item()])\n",
        "\n",
        "    return decoded_words, decoder_attn\n",
        "\n",
        "def evaluateRandomly(encoder, decoder, pairs, n=10):\n",
        "    for i in range(n):\n",
        "        pair = random.choice(pairs)\n",
        "        print('>', pair[0])\n",
        "        print('=', pair[1])\n",
        "        output_words, _ = evaluate(encoder, decoder, pair[0], input_lang, output_lang)\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        print('<', output_sentence)\n",
        "        print('')"
      ],
      "metadata": {
        "id": "hszxcvZwXHU3"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Executando o Treinamento\n",
        "\n",
        "Tudo pronto\\! Nesta célula, definimos os hiperparâmetros finais (tamanho da camada oculta, tamanho do lote, etc.), chamamos nossa função `get_dataloader` para preparar os dados e, finalmente, iniciamos o treinamento com a função `train`.\n",
        "\n",
        "-----"
      ],
      "metadata": {
        "id": "-NBlokUEXK71"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Bloco de código para iniciar o treinamento ---\n",
        "\n",
        "# Defina os hiperparâmetros\n",
        "hidden_size = 256\n",
        "batch_size = 32\n",
        "MAX_LENGTH = 10        # Frases com até 10 palavras (incluindo pontuação)\n",
        "MAX_VOCAB_SIZE = 1000  # Limite de 1000 palavras mais comuns\n",
        "MAX_PAIRS = 10000      # Limite de 10.000 frases para treinar\n",
        "\n",
        "# Carrega os dados usando a nossa função customizada\n",
        "# lang1='eng', lang2='por', reverse=True -> para traduzir de POR para ENG\n",
        "# A variável 'pairs' é retornada para ser usada na avaliação\n",
        "input_lang, output_lang, train_dataloader, pairs = get_dataloader(\n",
        "    batch_size,\n",
        "    'por',\n",
        "    'eng',\n",
        "    device,\n",
        "    max_vocab_size=MAX_VOCAB_SIZE,\n",
        "    max_pairs=MAX_PAIRS,\n",
        "    reverse=False\n",
        ")\n",
        "\n",
        "# Inicializa os modelos\n",
        "encoder = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
        "decoder = AttnDecoderRNN(hidden_size, output_lang.n_words).to(device)\n",
        "\n",
        "# Inicia o treinamento\n",
        "train(train_dataloader, encoder, decoder, n_epochs=40, print_every=5, plot_every=5)\n"
      ],
      "metadata": {
        "id": "5uID2w7FXnYF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "728d67f9-8b22-488b-d057-3244f4b3ef6d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lendo as linhas...\n",
            "Lidos 196350 pares de sentenças\n",
            "Contagem de palavras completa.\n",
            "Vocabulário limitado criado. Input: 1001 palavras, Output: 1001 palavras.\n",
            "Dataset final com 10000 pares de sentenças.\n",
            "==================================================\n",
            "⏳ Tempo decorrido: 0m 44s (- 5m 11s)\n",
            "📅 Época: 5/40 (12.50%)\n",
            "📉 Loss médio: 0.9828\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "⏳ Tempo decorrido: 1m 23s (- 4m 9s)\n",
            "📅 Época: 10/40 (25.00%)\n",
            "📉 Loss médio: 0.1464\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "⏳ Tempo decorrido: 2m 2s (- 3m 24s)\n",
            "📅 Época: 15/40 (37.50%)\n",
            "📉 Loss médio: 0.0581\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "⏳ Tempo decorrido: 2m 41s (- 2m 41s)\n",
            "📅 Época: 20/40 (50.00%)\n",
            "📉 Loss médio: 0.0403\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "⏳ Tempo decorrido: 3m 19s (- 1m 59s)\n",
            "📅 Época: 25/40 (62.50%)\n",
            "📉 Loss médio: 0.0362\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "⏳ Tempo decorrido: 3m 58s (- 1m 19s)\n",
            "📅 Época: 30/40 (75.00%)\n",
            "📉 Loss médio: 0.0301\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "⏳ Tempo decorrido: 4m 37s (- 0m 39s)\n",
            "📅 Época: 35/40 (87.50%)\n",
            "📉 Loss médio: 0.0278\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "⏳ Tempo decorrido: 5m 16s (- 0m 0s)\n",
            "📅 Época: 40/40 (100.00%)\n",
            "📉 Loss médio: 0.0270\n",
            "==================================================\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Avaliando o modelo\n",
        "\n",
        "Após o término do treinamento, mudamos os modelos para o modo de avaliação (`.eval()`) e chamamos `evaluateRandomly` para ver alguns resultados.\n",
        "\n",
        "-----"
      ],
      "metadata": {
        "id": "-YahdILSYntS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Avalia resultados aleatórios\n",
        "encoder.eval()\n",
        "decoder.eval()\n",
        "evaluateRandomly(encoder, decoder, pairs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2kYNHArDRWZ-",
        "outputId": "03e7dee5-6787-48f1-e198-2cb4213ef687"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> o tom sabe nadar ?\n",
            "= is tom able to swim ?\n",
            "< is tom able to swim ? <EOS>\n",
            "\n",
            "> quem estava jogando ?\n",
            "= who was playing ?\n",
            "< who was playing ? <EOS>\n",
            "\n",
            "> tom nao quer ir a igreja .\n",
            "= tom doesn t want to go to church .\n",
            "< tom doesn t want to go to church . <EOS>\n",
            "\n",
            "> segunda feira e um dia dificil .\n",
            "= monday is a difficult day .\n",
            "< monday is a difficult day . <EOS>\n",
            "\n",
            "> sabe o que tom quer de natal ?\n",
            "= do you know what tom wants for christmas ?\n",
            "< do you know what tom wants for christmas christmas for\n",
            "\n",
            "> tom diz nao precisar de dinheiro .\n",
            "= tom says he doesn t need money .\n",
            "< tom says he doesn t need money . <EOS>\n",
            "\n",
            "> e melhor eu ir para casa .\n",
            "= i d better go home .\n",
            "< i d better best home . <EOS>\n",
            "\n",
            "> voce e novo ?\n",
            "= are you new ?\n",
            "< are you new ? <EOS>\n",
            "\n",
            "> eu sei por que isso aconteceu .\n",
            "= i know why that happened .\n",
            "< i know why that happened . <EOS>\n",
            "\n",
            "> voce nao me pediu nada .\n",
            "= you haven t asked me anything .\n",
            "< you haven t asked me for me anything . <EOS>\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Métricas de Desempenho: Calculando o BLEU Score\n",
        "\n",
        "A métrica mais comum para tradução automática é o **BLEU (Bilingual Evaluation Understudy)**. De forma simples, o BLEU compara a tradução gerada pelo seu modelo com uma ou mais traduções humanas de referência. Ele gera uma pontuação de 0 a 1 (ou 0 a 100), onde valores mais altos indicam que a tradução do modelo é mais similar à tradução de referência.\n",
        "\n",
        "-----"
      ],
      "metadata": {
        "id": "5AFtKjD1YyKA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sacrebleu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--WbiKTebGsF",
        "outputId": "1120e98d-d16b-4dcb-97e4-0f6bb9e814a1"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.11/dist-packages (2.5.1)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (3.2.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (2024.11.6)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (2.0.2)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (0.4.6)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (5.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sacrebleu\n",
        "\n",
        "def calculate_bleu_with_sacrebleu(pairs, encoder, decoder, input_lang, output_lang):\n",
        "    \"\"\"\n",
        "    Calcula a pontuação BLEU usando a biblioteca externa sacrebleu.\n",
        "    \"\"\"\n",
        "    print(\"Calculando a pontuação BLEU com sacrebleu...\")\n",
        "\n",
        "    # sacrebleu espera listas de sentenças (strings), não de tokens\n",
        "    candidates = []\n",
        "    references = []\n",
        "\n",
        "    for pair in pairs:\n",
        "        source_sentence = pair[0]\n",
        "        # A referência já é uma string, que é o que precisamos\n",
        "        reference_sentence = pair[1]\n",
        "\n",
        "        # Gera a tradução (candidata) com o modelo\n",
        "        output_words, _ = evaluate(encoder, decoder, source_sentence, input_lang, output_lang)\n",
        "\n",
        "        if output_words[-1] == '<EOS>':\n",
        "            output_words = output_words[:-1]\n",
        "\n",
        "        # Junta os tokens da candidata em uma única string\n",
        "        candidate_sentence = ' '.join(output_words)\n",
        "\n",
        "        candidates.append(candidate_sentence)\n",
        "        references.append(reference_sentence)\n",
        "\n",
        "    # A API do sacrebleu espera a lista de referências dentro de outra lista,\n",
        "    # pois suporta múltiplas referências por sentença.\n",
        "    # A pontuação já vem na escala de 0 a 100.\n",
        "    bleu = sacrebleu.corpus_bleu(candidates, [references])\n",
        "\n",
        "    print(f\"Pontuação BLEU (sacrebleu): {bleu.score:.2f}\")\n",
        "\n",
        "    return bleu.score"
      ],
      "metadata": {
        "id": "j6bf133Ka1Pj"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bleu_value = calculate_bleu_with_sacrebleu(pairs, encoder, decoder, input_lang, output_lang)"
      ],
      "metadata": {
        "id": "ttP8PPGAa9r9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46937aee-1ce6-42a5-a7da-f6d1fe8acdff"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculando a pontuação BLEU com sacrebleu...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sacrebleu:That's 100 lines that end in a tokenized period ('.')\n",
            "WARNING:sacrebleu:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "WARNING:sacrebleu:If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pontuação BLEU (sacrebleu): 86.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Salva apenas os pesos (o dicionário de estado)\n",
        "torch.save(encoder.state_dict(), 'gru_encoder_pesos.pth')\n",
        "torch.save(decoder.state_dict(), 'gru_decoder_pesos.pth')\n",
        "\n",
        "print(\"Pesos do modelo GRU salvos com sucesso!\")\n",
        "\n",
        "# Salva o modelo completo\n",
        "torch.save(encoder, 'gru_encoder_completo.pth')\n",
        "torch.save(decoder, 'gru_decoder_completo.pth')\n",
        "\n",
        "print(\"Modelo GRU completo salvo com sucesso!\")"
      ],
      "metadata": {
        "id": "GwgsYD7ca-x2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f103d62-d621-4804-965e-692aa4868c9f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pesos do modelo GRU salvos com sucesso!\n",
            "Modelo GRU completo salvo com sucesso!\n"
          ]
        }
      ]
    }
  ]
}