{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gabrielcampanile/Neural-Network/blob/main/Projeto%20Final%20-%20Translator/GRU_bidirecional.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tradutor Inglês-Português com Redes Sequência-a-Sequência, Atenção e GRU Bidirecional\n",
        "\n",
        "Este notebook implementa um modelo de tradução automática de inglês para português, baseado no tutorial \"NLP From Scratch: Translation with a Sequence to Sequence Network and Attention\" do PyTorch, com aprimoramento para usar redes GRU bidirecionais.\n",
        "\n",
        "A arquitetura utilizada é um modelo **Sequence-to-Sequence (Seq2Seq)** composto por um **Encoder** e um **Decoder** com redes neurais recorrentes (**GRU Bidirecional** no Encoder). Para melhorar a performance, implementamos um **Mecanismo de Atenção (Attention)**, que permite ao modelo focar em partes específicas da frase de entrada ao gerar a tradução.\n",
        "\n",
        "**Estratégia Principal:** Para garantir que o treinamento seja computacionalmente viável e rápido, seguimos a orientação de limitar o tamanho do nosso dataset. Em vez de usar todas as frases disponíveis, criamos um vocabulário com as palavras mais frequentes e filtramos o dataset para usar apenas um número limitado de frases que podem ser formadas com esse vocabulário.\n",
        "\n",
        "----\n"
      ],
      "metadata": {
        "id": "NTnVUPlcVUr5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Para plotagem no notebook\n",
        "%matplotlib inline\n",
        "\n",
        "# Imports principais\n",
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import re\n",
        "import random\n",
        "import time\n",
        "import math\n",
        "\n",
        "# Imports do PyTorch e utilidades\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
        "\n",
        "# Imports para plotagem\n",
        "import matplotlib.pyplot as plt\n",
        "#plt.switch_backend('agg')\n",
        "import matplotlib.ticker as ticker\n",
        "\n",
        "# Configuração do dispositivo (GPU ou CPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Usando dispositivo: {device}\")\n",
        "\n",
        "# Tokens especiais para marcar início e fim de sentenças\n",
        "SOS_token = 0\n",
        "EOS_token = 1\n"
      ],
      "metadata": {
        "id": "P36Ivcu6Vg1i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1ebbd3f-70ff-4fa9-c81c-a7d415bcc81e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Usando dispositivo: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparação dos Dados: Classes e Funções de Normalização\n",
        "\n",
        "Para trabalhar com texto, primeiro precisamos processá-lo.\n",
        "\n",
        "1.  **Classe `Lang`**: Uma classe auxiliar para criar um vocabulário. Ela mapeia cada palavra única para um índice numérico (e vice-versa) e conta a frequência de cada palavra.\n",
        "2.  **Normalização de Strings**: Funções para converter o texto para um formato padrão: minúsculas, remoção de acentos e de caracteres especiais. Isso reduz a complexidade do vocabulário.\n",
        "\n",
        "-----"
      ],
      "metadata": {
        "id": "asfIFZQ2VpHr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokens especiais atualizados\n",
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "UNK_token = 2 # Novo token para palavras desconhecidas\n",
        "\n",
        "# Classe Lang atualizada para incluir UNK\n",
        "class Lang:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2index = {}\n",
        "        self.word2count = {}\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\", 2: \"<UNK>\"}\n",
        "        self.n_words = 3\n",
        "\n",
        "    def addSentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.addWord(word)\n",
        "\n",
        "    def addWord(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words\n",
        "            self.word2count[word] = 1\n",
        "            self.index2word[self.n_words] = word\n",
        "            self.n_words += 1\n",
        "        else:\n",
        "            self.word2count[word] += 1\n",
        "\n",
        "# Converte uma string Unicode para ASCII puro\n",
        "def unicodeToAscii(s):\n",
        "    return ''.join(\n",
        "        c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn'\n",
        "    )\n",
        "\n",
        "# Deixa em minúsculo, remove espaços e caracteres não-letra\n",
        "def normalizeString(s):\n",
        "    s = unicodeToAscii(s.lower().strip())\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
        "    s = re.sub(r'\\s+', ' ', s).strip()\n",
        "    return s"
      ],
      "metadata": {
        "id": "En4yDZRMVvWU"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Leitura e Filtragem de Dados\n",
        "\n",
        "Aqui definimos as funções para carregar, processar e preparar o dataset para o treinamento. Esta é a etapa mais customizada do nosso projeto.\n",
        "\n",
        "1.  `readLangs`: Lê o arquivo de texto `eng-por.txt` e o divide em pares de sentenças.\n",
        "2.  `prepareDataWithVocabLimit`: Nossa função principal de preparação. Ela lê todos os pares, conta a frequência das palavras, cria vocabulários com as `N` palavras mais comuns, e então filtra o dataset para manter apenas um número limitado de frases curtas que usam exclusivamente palavras desses vocabulários.\n",
        "3.  `get_dataloader`: Junta tudo, executa a preparação e cria um `DataLoader` do PyTorch, que nos ajudará a alimentar o modelo com dados em lotes (batches) de forma eficiente.\n",
        "\n",
        "-----"
      ],
      "metadata": {
        "id": "568AYrZ_V8VX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def readLangs(lang1, lang2, reverse=False):\n",
        "    print(\"Lendo as linhas...\")\n",
        "    # Assumimos que o arquivo limpo está em 'data/eng-por.txt'\n",
        "    lines = open(f'data/{lang1}-{lang2}.txt', encoding='utf-8').read().strip().split('\\n')\n",
        "\n",
        "    pairs = []\n",
        "    for l in lines:\n",
        "      line_parts = l.split('\\t')\n",
        "      if len(line_parts) == 2:\n",
        "        pairs.append([normalizeString(s) for s in line_parts])\n",
        "\n",
        "    if reverse:\n",
        "        pairs = [list(reversed(p)) for p in pairs]\n",
        "        input_lang = Lang(lang2)\n",
        "        output_lang = Lang(lang1)\n",
        "    else:\n",
        "        input_lang = Lang(lang1)\n",
        "        output_lang = Lang(lang2)\n",
        "\n",
        "    return input_lang, output_lang, pairs\n",
        "\n",
        "def prepareDataWithVocabLimit(lang1, lang2, reverse=False, max_vocab_size=4000, max_pairs=None):\n",
        "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
        "    print(f\"Lidos {len(pairs)} pares de sentenças\")\n",
        "\n",
        "    temp_input_lang = Lang(input_lang.name)\n",
        "    temp_output_lang = Lang(output_lang.name)\n",
        "    for pair in pairs:\n",
        "        temp_input_lang.addSentence(pair[0])\n",
        "        temp_output_lang.addSentence(pair[1])\n",
        "    print(\"Contagem de palavras completa.\")\n",
        "\n",
        "    sorted_input_vocab = sorted(temp_input_lang.word2count.items(), key=lambda item: item[1], reverse=True)\n",
        "    sorted_output_vocab = sorted(temp_output_lang.word2count.items(), key=lambda item: item[1], reverse=True)\n",
        "\n",
        "    input_lang = Lang(input_lang.name)\n",
        "    output_lang = Lang(output_lang.name)\n",
        "    for word, _ in sorted_input_vocab[:max_vocab_size-2]:\n",
        "        input_lang.addWord(word)\n",
        "    for word, _ in sorted_output_vocab[:max_vocab_size-2]:\n",
        "        output_lang.addWord(word)\n",
        "    print(f\"Vocabulário limitado criado. Input: {input_lang.n_words} palavras, Output: {output_lang.n_words} palavras.\")\n",
        "\n",
        "    filtered_pairs = []\n",
        "    for pair in pairs:\n",
        "        if len(pair[0].split(' ')) >= MAX_LENGTH or len(pair[1].split(' ')) >= MAX_LENGTH:\n",
        "            continue\n",
        "        input_valid = all(word in input_lang.word2index for word in pair[0].split(' '))\n",
        "        output_valid = all(word in output_lang.word2index for word in pair[1].split(' '))\n",
        "        if input_valid and output_valid:\n",
        "            filtered_pairs.append(pair)\n",
        "\n",
        "    if max_pairs:\n",
        "        random.shuffle(filtered_pairs)\n",
        "        filtered_pairs = filtered_pairs[:max_pairs]\n",
        "\n",
        "    print(f\"Dataset final com {len(filtered_pairs)} pares de sentenças.\")\n",
        "    return input_lang, output_lang, filtered_pairs\n",
        "\n",
        "def get_dataloader(batch_size, lang1, lang2, device, max_vocab_size=4000, max_pairs=None, reverse=True):\n",
        "    input_lang, output_lang, pairs = prepareDataWithVocabLimit(lang1, lang2, reverse, max_vocab_size, max_pairs)\n",
        "    n = len(pairs)\n",
        "    input_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n",
        "    target_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n",
        "\n",
        "    for idx, (inp, tgt) in enumerate(pairs):\n",
        "        inp_ids = [input_lang.word2index[word] for word in inp.split(' ')]\n",
        "        tgt_ids = [output_lang.word2index[word] for word in tgt.split(' ')]\n",
        "        inp_ids.append(EOS_token)\n",
        "        tgt_ids.append(EOS_token)\n",
        "        input_ids[idx, :len(inp_ids)] = inp_ids\n",
        "        target_ids[idx, :len(tgt_ids)] = tgt_ids\n",
        "\n",
        "    train_data = TensorDataset(torch.LongTensor(input_ids).to(device),\n",
        "                               torch.LongTensor(target_ids).to(device))\n",
        "    train_sampler = RandomSampler(train_data)\n",
        "    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "    return input_lang, output_lang, train_dataloader, pairs"
      ],
      "metadata": {
        "id": "lpwQtCN9WBNt"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A Arquitetura do Modelo: Seq2Seq com Atenção e GRU Bidirecional\n",
        "\n",
        "#### Encoder\n",
        "\n",
        "O `EncoderRNN` processa a frase de entrada e a comprime em um vetor de contexto. Ele usa uma camada de *Embedding* para transformar os índices das palavras em vetores densos, e uma camada **GRU Bidirecional** para processar a sequência em ambas as direções (da esquerda para a direita e da direita para a esquerda). Isso permite que o encoder capture dependências de longo alcance e tenha uma representação mais rica do contexto da frase de entrada.\n",
        "\n",
        "#### Attention Decoder\n",
        "\n",
        "O `AttnDecoderRNN` gera a frase de saída. A cada passo, ele usa o mecanismo `BahdanauAttention` para calcular pesos de atenção, criando um vetor de contexto ponderado que foca nas partes mais relevantes da entrada. Este contexto (agora derivado das saídas bidirecionais do encoder) é combinado com a palavra anterior para prever a próxima palavra da tradução.\n",
        "\n",
        "-----"
      ],
      "metadata": {
        "id": "OmrLACVrWHnN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, dropout_p=0.1):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
        "\n",
        "        # A MUDANÇA PRINCIPAL ESTÁ AQUI: adicionamos bidirectional=True\n",
        "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True, bidirectional=True)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "\n",
        "    def forward(self, input):\n",
        "        # A lógica do forward continua a mesma\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        output, hidden = self.gru(embedded)\n",
        "        return output, hidden\n",
        "\n",
        "class BahdanauAttention(nn.Module):\n",
        "    def __init__(self, hidden_size):\n",
        "        super(BahdanauAttention, self).__init__()\n",
        "        self.Wa = nn.Linear(hidden_size, hidden_size)\n",
        "        # MUDANÇA: Ua agora recebe a saída do encoder bidirecional (hidden_size * 2)\n",
        "        self.Ua = nn.Linear(hidden_size * 2, hidden_size)\n",
        "        self.Va = nn.Linear(hidden_size, 1)\n",
        "\n",
        "    def forward(self, query, keys):\n",
        "        # A lógica do forward continua a mesma\n",
        "        scores = self.Va(torch.tanh(self.Wa(query) + self.Ua(keys)))\n",
        "        scores = scores.squeeze(2).unsqueeze(1)\n",
        "        weights = F.softmax(scores, dim=-1)\n",
        "        # O 'context' agora terá hidden_size * 2, pois é um produto de 'weights' e 'keys'\n",
        "        context = torch.bmm(weights, keys)\n",
        "        return context, weights\n",
        "\n",
        "class AttnDecoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, dropout_p=0.1):\n",
        "        super(AttnDecoderRNN, self).__init__()\n",
        "\n",
        "        # O tamanho do embedding é o mesmo\n",
        "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
        "\n",
        "        # A classe de Atenção já foi ajustada, aqui apenas a instanciamos\n",
        "        self.attention = BahdanauAttention(hidden_size)\n",
        "\n",
        "        # MUDANÇA: Camada para combinar os hidden states do encoder (frente e trás)\n",
        "        self.fc_hidden = nn.Linear(hidden_size * 2, hidden_size)\n",
        "\n",
        "        # MUDANÇA: A entrada da GRU agora é o embedding + o contexto da atenção (hidden_size * 2)\n",
        "        self.gru = nn.GRU(hidden_size + (hidden_size * 2), hidden_size, batch_first=True)\n",
        "\n",
        "        self.out = nn.Linear(hidden_size, output_size)\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "\n",
        "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
        "        batch_size = encoder_outputs.size(0)\n",
        "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token)\n",
        "\n",
        "        # MUDANÇA: Combinar os estados ocultos do encoder\n",
        "        # O encoder_hidden tem shape (2, batch_size, hidden_size)\n",
        "        # Concatenamos ao longo da dimensão da feature para obter (1, batch_size, hidden_size * 2)\n",
        "        encoder_hidden_concat = torch.cat((encoder_hidden[0:1], encoder_hidden[1:2]), dim=2)\n",
        "        # Passamos pela camada linear para obter o shape esperado pelo decoder (1, batch_size, hidden_size)\n",
        "        decoder_hidden = torch.tanh(self.fc_hidden(encoder_hidden_concat))\n",
        "\n",
        "        decoder_outputs = []\n",
        "        attentions = []\n",
        "\n",
        "        for i in range(MAX_LENGTH):\n",
        "            decoder_output, decoder_hidden, attn_weights = self.forward_step(\n",
        "                decoder_input, decoder_hidden, encoder_outputs\n",
        "            )\n",
        "            decoder_outputs.append(decoder_output)\n",
        "            attentions.append(attn_weights)\n",
        "\n",
        "            if target_tensor is not None:\n",
        "                decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing\n",
        "            else:\n",
        "                _, topi = decoder_output.topk(1)\n",
        "                decoder_input = topi.squeeze(-1).detach()\n",
        "\n",
        "        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n",
        "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
        "        attentions = torch.cat(attentions, dim=1)\n",
        "\n",
        "        return decoder_outputs, decoder_hidden, attentions\n",
        "\n",
        "    def forward_step(self, input, hidden, encoder_outputs):\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "\n",
        "        query = hidden.permute(1, 0, 2)\n",
        "        # O context retornado pela atenção agora tem hidden_size * 2\n",
        "        context, attn_weights = self.attention(query, encoder_outputs)\n",
        "\n",
        "        # MUDANÇA: A concatenação agora usa o 'context' maior\n",
        "        input_gru = torch.cat((embedded, context), dim=2)\n",
        "\n",
        "        output, hidden = self.gru(input_gru, hidden)\n",
        "        output = self.out(output)\n",
        "\n",
        "        return output, hidden, attn_weights"
      ],
      "metadata": {
        "id": "tD_bvlMPWUD-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Treinamento do Modelo\n",
        "\n",
        "Definimos agora as funções para treinar nosso modelo.\n",
        "\n",
        "  - `train_epoch`: Executa uma única época de treinamento. Para cada lote de dados, ela passa as frases pelo encoder e decoder, calcula a perda (o quão errada a previsão foi) e atualiza os pesos das redes usando os otimizadores.\n",
        "  - `train`: Orquestra o processo de treinamento completo por várias épocas, chamando `train_epoch` repetidamente. Ela também monitora a perda, exibe o progresso e o tempo decorrido.\n",
        "  - `asMinutes` e `timeSince`: Funções auxiliares para formatar o tempo de treinamento.\n",
        "\n",
        "-----"
      ],
      "metadata": {
        "id": "lcGV-iU4WX10"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
      ],
      "metadata": {
        "id": "0os6Zie9WaMu"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion):\n",
        "    total_loss = 0\n",
        "    for data in dataloader:\n",
        "        input_tensor, target_tensor = data\n",
        "\n",
        "        encoder_optimizer.zero_grad()\n",
        "        decoder_optimizer.zero_grad()\n",
        "\n",
        "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
        "        decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden, target_tensor)\n",
        "\n",
        "        loss = criterion(\n",
        "            decoder_outputs.view(-1, decoder_outputs.size(-1)),\n",
        "            target_tensor.view(-1)\n",
        "        )\n",
        "        loss.backward()\n",
        "\n",
        "        encoder_optimizer.step()\n",
        "        decoder_optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(dataloader)\n",
        "\n",
        "def train(train_dataloader, encoder, decoder, n_epochs, learning_rate=0.001, print_every=100, plot_every=100):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0\n",
        "    plot_loss_total = 0\n",
        "\n",
        "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        loss = train_epoch(train_dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if epoch % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print(\"=\" * 50)\n",
        "            print(f\"⏳ Tempo decorrido: {timeSince(start, epoch / n_epochs)}\")\n",
        "            print(f\"📅 Época: {epoch}/{n_epochs} ({epoch / n_epochs * 100:.2f}%)\")\n",
        "            print(f\"📉 Loss médio: {print_loss_avg:.4f}\")\n",
        "            print(\"=\" * 50 + \"\\n\")\n",
        "\n",
        "        if epoch % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plot_loss_total = 0\n",
        "\n",
        "    showPlot(plot_losses)"
      ],
      "metadata": {
        "id": "hELx7ooxW01V"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plotando os Resultados\n",
        "\n",
        "Uma função simples para plotar a perda (loss) ao longo do treinamento. Ver a perda diminuir é um bom sinal de que o modelo está aprendendo.\n",
        "\n",
        "-----"
      ],
      "metadata": {
        "id": "dua2iVhuW9jx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def showPlot(points):\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots()\n",
        "    loc = ticker.MultipleLocator(base=0.2)\n",
        "    ax.yaxis.set_major_locator(loc)\n",
        "    plt.plot(points)\n",
        "    plt.xlabel(\"Épocas (x100)\")\n",
        "    plt.ylabel(\"Perda (Loss)\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "U9jmJf_tW-QE"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Avaliação e Visualização\n",
        "\n",
        "Após o treinamento, precisamos de funções para testar nosso modelo.\n",
        "\n",
        "  - `evaluate`: Recebe uma frase em português, a traduz para o inglês e retorna a tradução.\n",
        "  - `evaluateRandomly`: Pega `n` frases aleatórias do nosso dataset de teste, exibe a entrada, o alvo (tradução correta) e a saída do modelo (tradução prevista). É ótima para uma avaliação qualitativa rápida.\n",
        "\n",
        "-----"
      ],
      "metadata": {
        "id": "zwNv9jS4XC1X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(encoder, decoder, sentence, input_lang, output_lang):\n",
        "    with torch.no_grad():\n",
        "        # Converte a sentença de entrada em um tensor de índices.\n",
        "        # Se uma palavra não for encontrada, usa o UNK_token.\n",
        "        input_indices = [input_lang.word2index.get(word, UNK_token) for word in sentence.split(' ')]\n",
        "        input_indices.append(EOS_token)\n",
        "        input_tensor = torch.tensor(input_indices, dtype=torch.long, device=device).view(1, -1)\n",
        "\n",
        "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
        "        decoder_outputs, decoder_hidden, decoder_attn = decoder(encoder_outputs, encoder_hidden)\n",
        "\n",
        "        _, topi = decoder_outputs.topk(1)\n",
        "        decoded_ids = topi.squeeze()\n",
        "\n",
        "        decoded_words = []\n",
        "        for idx in decoded_ids:\n",
        "            if idx.item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            # O output não precisa de UNK, pois ele sempre gera palavras de seu vocabulário\n",
        "            decoded_words.append(output_lang.index2word[idx.item()])\n",
        "\n",
        "    return decoded_words, decoder_attn\n",
        "\n",
        "def evaluateRandomly(encoder, decoder, pairs, n=10):\n",
        "    for i in range(n):\n",
        "        pair = random.choice(pairs)\n",
        "        print('>', pair[0])\n",
        "        print('=', pair[1])\n",
        "        output_words, _ = evaluate(encoder, decoder, pair[0], input_lang, output_lang)\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        print('<', output_sentence)\n",
        "        print('')"
      ],
      "metadata": {
        "id": "hszxcvZwXHU3"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Executando o Treinamento\n",
        "\n",
        "Tudo pronto\\! Nesta célula, definimos os hiperparâmetros finais (tamanho da camada oculta, tamanho do lote, etc.), chamamos nossa função `get_dataloader` para preparar os dados e, finalmente, iniciamos o treinamento com a função `train`.\n",
        "\n",
        "-----"
      ],
      "metadata": {
        "id": "-NBlokUEXK71"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Bloco de código para iniciar o treinamento ---\n",
        "\n",
        "# Defina os hiperparâmetros\n",
        "hidden_size = 256\n",
        "batch_size = 32\n",
        "MAX_LENGTH = 10        # Frases com até 10 palavras (incluindo pontuação)\n",
        "MAX_VOCAB_SIZE = 1000  # Limite de 1000 palavras mais comuns\n",
        "MAX_PAIRS = 10000      # Limite de 10.000 frases para treinar\n",
        "\n",
        "# Carrega os dados usando a nossa função customizada\n",
        "# lang1='eng', lang2='por', reverse=True -> para traduzir de POR para ENG\n",
        "# A variável 'pairs' é retornada para ser usada na avaliação\n",
        "input_lang, output_lang, train_dataloader, pairs = get_dataloader(\n",
        "    batch_size,\n",
        "    'por',\n",
        "    'eng',\n",
        "    device,\n",
        "    max_vocab_size=MAX_VOCAB_SIZE,\n",
        "    max_pairs=MAX_PAIRS,\n",
        "    reverse=False\n",
        ")\n",
        "\n",
        "# Inicializa os modelos\n",
        "encoder = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
        "decoder = AttnDecoderRNN(hidden_size, output_lang.n_words).to(device)\n",
        "\n",
        "# Inicia o treinamento\n",
        "train(train_dataloader, encoder, decoder, n_epochs=40, print_every=5, plot_every=5)\n"
      ],
      "metadata": {
        "id": "5uID2w7FXnYF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7a99a8ba-e078-4488-e75a-d93979f0584c"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lendo as linhas...\n",
            "Lidos 196350 pares de sentenças\n",
            "Contagem de palavras completa.\n",
            "Vocabulário limitado criado. Input: 1001 palavras, Output: 1001 palavras.\n",
            "Dataset final com 10000 pares de sentenças.\n",
            "==================================================\n",
            "⏳ Tempo decorrido: 0m 40s (- 4m 41s)\n",
            "📅 Época: 5/40 (12.50%)\n",
            "📉 Loss médio: 1.0126\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "⏳ Tempo decorrido: 1m 19s (- 3m 59s)\n",
            "📅 Época: 10/40 (25.00%)\n",
            "📉 Loss médio: 0.1480\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "⏳ Tempo decorrido: 1m 59s (- 3m 18s)\n",
            "📅 Época: 15/40 (37.50%)\n",
            "📉 Loss médio: 0.0553\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "⏳ Tempo decorrido: 2m 38s (- 2m 38s)\n",
            "📅 Época: 20/40 (50.00%)\n",
            "📉 Loss médio: 0.0423\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "⏳ Tempo decorrido: 3m 18s (- 1m 59s)\n",
            "📅 Época: 25/40 (62.50%)\n",
            "📉 Loss médio: 0.0327\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "⏳ Tempo decorrido: 3m 58s (- 1m 19s)\n",
            "📅 Época: 30/40 (75.00%)\n",
            "📉 Loss médio: 0.0313\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "⏳ Tempo decorrido: 4m 37s (- 0m 39s)\n",
            "📅 Época: 35/40 (87.50%)\n",
            "📉 Loss médio: 0.0256\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "⏳ Tempo decorrido: 5m 16s (- 0m 0s)\n",
            "📅 Época: 40/40 (100.00%)\n",
            "📉 Loss médio: 0.0282\n",
            "==================================================\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAGyCAYAAAAYveVYAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAQe5JREFUeJzt3Xl8VPW9//H3zCQzSSAbBhICYUcWgSQSQRBrlSgq2np/3hatlUjrRkHRuKIItSrY69VSNEJFRW1rpa61LiiiolS8aEIUkEXWhCUBhOz7zPn9ETJkzEKWyZzJ5PV8PM4jme+cc+ZzApo33/M936/FMAxDAAAAAcJqdgEAAADeRLgBAAABhXADAAACCuEGAAAEFMINAAAIKIQbAAAQUAg3AAAgoASZXYCvuVwuHTx4UOHh4bJYLGaXAwAAWsAwDBUXFys+Pl5Wa/N9M10u3Bw8eFAJCQlmlwEAANogNzdXffv2bXafLhduwsPDJdX+cCIiIkyuBgAAtERRUZESEhLcv8eb0+XCTd2tqIiICMINAACdTEuGlDCgGAAABBTCDQAACCiEGwAAEFAINwAAIKAQbgAAQEAh3AAAgIBCuAEAAAGFcAMAAAIK4QYAAAQUwg0AAAgohBsAABBQCDcAACCgEG686FhplXbkF5tdBgAAXRrhxktWf5evMx9arTtf/cbsUgAA6NIIN14yone4JOm7g0WqqHaaXA0AAF2XqeHms88+0+WXX674+HhZLBa99dZbpzzm008/1ZlnnimHw6EhQ4bohRde6PA6W6JPVKh6hjtU4zK0+UCh2eUAANBlmRpuSktLlZiYqIyMjBbtv2fPHk2dOlXnn3++srOzddttt+n666/XBx980MGVnprFYlFyQpQkaWNOgam1AADQlQWZ+eGXXHKJLrnkkhbvv2zZMg0cOFCPP/64JGnEiBFat26d/vSnP2nKlCmNHlNZWanKykr366KiovYV3YzkftH68Lt8bcw93mGfAQAAmtepxtysX79eqampHm1TpkzR+vXrmzxm0aJFioyMdG8JCQkdVl9yvyhJ9NwAAGCmThVu8vLyFBsb69EWGxuroqIilZeXN3rM3LlzVVhY6N5yc3M7rL4xfSNltUiHCit0qLDxegAAQMfqVOGmLRwOhyIiIjy2jhJmD9LwuNrzZ9N7AwCAKTpVuImLi1N+fr5HW35+viIiIhQaGmpSVZ7O7B8lSdqYW2BqHQAAdFWdKtxMmDBBa9as8WhbvXq1JkyYYFJFDSUnREuSsvYxqBgAADOYGm5KSkqUnZ2t7OxsSbWPemdnZysnJ0dS7XiZ6dOnu/e/+eabtXv3bt19993atm2bnn76af3zn//U7bffbkb5jaobVLzpQKGqalzmFgMAQBdkarj5+uuvlZycrOTkZElSenq6kpOTNX/+fEnSoUOH3EFHkgYOHKh3331Xq1evVmJioh5//HE9++yzTT4GboaBMd0UGRqsyhqXtuV13GPnAACgcRbDMAyzi/CloqIiRUZGqrCwsMMGF1+3YoM+3X5ED/7sDKVNHNAhnwEAQFfSmt/fnWrMTWdRN+5mYw7jbgAA8DXCTQdwT+bHE1MAAPgc4aYDJJ5YY2rfD2X6oaSy+Z0BAIBXEW46QGRosIb06i5Jyqb3BgAAnyLcdBBWCAcAwByEmw6S3O/EoGJWCAcAwKcINx2kblDxN7mFcrq61NP2AACYinDTQU6PDVeY3aaSyhrtPFxidjkAAHQZhJsOYrNalNg3ShLz3QAA4EuEmw7knu+GQcUAAPgM4aYDMagYAADfI9x0oKQTj4N/f7hERRXV5hYDAEAXQbjpQD3DHUroESrDkL7NLTS7HAAAugTCTQdjEU0AAHyLcNPBWEQTAADfItx0MPeg4pzjMgwm8wMAoKMRbjrYyN4RsgdZdbysWvt+KDO7HAAAAh7hpoPZg6waFR8hiUfCAQDwBcKND5y8NVVgbiEAAHQBhBsfYKZiAAB8h3DjA3U9N1sPFam8ymlyNQAABDbCjQ/ER4aoV7hDNS5Dmw8ymR8AAB2JcOMDFoul3q0pBhUDANCRCDc+wqBiAAB8g3DjI8knFtEk3AAA0LEINz4yum+kbFaL8ooqdKiw3OxyAAAIWIQbHwmzB2l4XLgkem8AAOhIhBsfYlAxAAAdj3DjQ2cyqBgAgA5HuPGhuiemNh0oVFWNy+RqAAAITIQbHxpwWpiiwoJVWePStrwis8sBACAgEW58yGKx8Eg4AAAdjHDjY3W3prIYVAwAQIcg3PgYK4QDANCxCDc+lpgQJYtFyjlWpqMllWaXAwBAwCHc+FhESLCG9OwuScqm9wYAAK8j3JjAfWsql3E3AAB4G+HGBKwQDgBAxyHcmKCu5+ab3AI5XYa5xQAAEGAINyYY2itc3ew2lVY59f3hYrPLAQAgoBBuTGCzWpTIZH4AAHQIwo1JWCEcAICOQbgxSXICg4oBAOgIhBuTJJ3oufn+cIkKy6vNLQYAgABCuDFJTHeH+vUIkyR9u7/A3GIAAAgghBsTsc4UAADeR7gxUbL7iSkGFQMA4C2EGxO5ZyrOLZBhMJkfAADeQLgx0YjeEbIHWVVQVq29P5SZXQ4AAAGBcGMie5BVo/tESuLWFAAA3kK4MVkyMxUDAOBVhBuTnRx3Q88NAADeQLgxWd3j4FsPFau8ymluMQAABADCjcl6R4YoNsIhp8vQpgOFZpcDAECnR7gxmcViqbfOFLemAABoL8KNH2CmYgAAvIdw4wfqBhVn5RxnMj8AANrJ9HCTkZGhAQMGKCQkROPHj9eGDRua3X/x4sUaNmyYQkNDlZCQoNtvv10VFRU+qrZjjO4TKZvVosPFlTpU2LmvBQAAs5kablauXKn09HQtWLBAWVlZSkxM1JQpU3T48OFG93/55Zd17733asGCBdq6dauee+45rVy5Uvfdd5+PK/euULtNI3qHS+LWFAAA7WVquHniiSd0ww03aMaMGRo5cqSWLVumsLAwPf/8843u/8UXX+icc87Rr371Kw0YMEAXXXSRrr766mZ7eyorK1VUVOSx+SMGFQMA4B2mhZuqqiplZmYqNTX1ZDFWq1JTU7V+/fpGj5k4caIyMzPdYWb37t167733dOmllzb5OYsWLVJkZKR7S0hI8O6FeIl7UHFugal1AADQ2ZkWbo4ePSqn06nY2FiP9tjYWOXl5TV6zK9+9Sv94Q9/0KRJkxQcHKzBgwfrpz/9abO3pebOnavCwkL3lpub69Xr8JYzTwwq3nSgUFU1LpOrAQCg8zJ9QHFrfPrpp1q4cKGefvppZWVl6Y033tC7776rhx56qMljHA6HIiIiPDZ/1P+0MEWHBauqxqWth/zz1hkAAJ1BkFkfHBMTI5vNpvz8fI/2/Px8xcXFNXrMAw88oGuvvVbXX3+9JGn06NEqLS3VjTfeqPvvv19Wa6fKah4sFouS+0Xr422HtTHnuBJPLKgJAABax7Q0YLfbNXbsWK1Zs8bd5nK5tGbNGk2YMKHRY8rKyhoEGJvNJkkBMT+Me4Vwxt0AANBmpvXcSFJ6errS0tKUkpKicePGafHixSotLdWMGTMkSdOnT1efPn20aNEiSdLll1+uJ554QsnJyRo/frx27typBx54QJdffrk75HRm7hXCeRwcAIA2MzXcTJs2TUeOHNH8+fOVl5enpKQkrVq1yj3IOCcnx6OnZt68ebJYLJo3b54OHDignj176vLLL9cjjzxi1iV41ZiESFksUs6xMh0tqVRMd4fZJQEA0OlYjEC4n9MKRUVFioyMVGFhoV8OLr7oT2u1I79Ey6en6MKRsac+AACALqA1v7877wjcAMVkfgAAtA/hxs+wQjgAAO1DuPEzdYOKv9lfIKerS90xBADAKwg3fmZIr+7q7ghSWZVTO/KLzS4HAIBOh3DjZ2xWixITIiVxawoAgLYg3PghBhUDANB2hBs/xArhAAC0HeHGDyWdWIZh5+ESFZZXm1sMAACdDOHGD53W3aH+p4VJkr6h9wYAgFYh3Pgp9yKaDCoGAKBVCDd+yr2IZi6DigEAaA3CjZ+qP1NxF1v+CwCAdiHc+KnhcRFyBFlVWF6tPUdLzS4HAIBOg3Djp+xBVo3uw2R+AAC0FuHGj52c74ZxNwAAtBThxo+5BxXTcwMAQIsRbvxYXc/NtrxilVXVmFsMAACdBOHGj/WODFVcRIicLkOb9heaXQ4AAJ0C4cbPsc4UAACtQ7jxcyfnu2FQMQAALUG48XN1g4qzmMwPAIAWIdz4uVHxkQqyWnSkuFIHCyvMLgcAAL9HuPFzoXabRvSOkMStKQAAWoJw0wnUX2cKAAA0j3DTCTCoGACAliPcdALJCbWDijcfLFJljdPkagAA8G+Em06g/2lh6tHNrqoal7YeKja7HAAA/BrhphOwWCxKToiSxK0pAABOhXDTSTCoGACAliHcdBLuFcJz6bkBAKA5hJtOYkzfSFksUu6xch0prjS7HAAA/BbhppMIDwnW6b3CJUnZLKIJAECTCDedCPPdAABwaoSbToRBxQAAnBrhphOpG1T8zf4COV2sEA4AQGMIN53IkJ7dFe4IUlmVU9vzmMwPAIDGEG46EavVosS6yfx4JBwAgEYRbjoZxt0AANA8wk0nwxNTAAA0j3DTySSdWCF815FSFZZVm1wNAAD+h3DTyfToZteA08IkSdn7C8wtBgAAP0S46YTc60xxawoAgAYIN50Qg4oBAGga4aYTSj4x7iY7t0AuJvMDAMAD4aYTGt47XI4gqwrLq7Xnh1KzywEAwK8QbjqhYJtVY/pGSuLWFAAAP0a46aQYVAwAQOMIN51Uct0yDPTcAADgIai1B7hcLq1du1aff/659u3bp7KyMvXs2VPJyclKTU1VQkJCR9SJH6nrudmWV6SyqhqF2Vv9RwkAQEBqcc9NeXm5Hn74YSUkJOjSSy/V+++/r4KCAtlsNu3cuVMLFizQwIEDdemll+rLL7/syJohKS4yRL0jQ+QypG/3F5pdDgAAfqPF/9w//fTTNWHCBC1fvlwXXnihgoODG+yzb98+vfzyy7rqqqt0//3364YbbvBqsfCU3C9KhzblaWNOgc4edJrZ5QAA4BdaHG4+/PBDjRgxotl9+vfvr7lz5+rOO+9UTk5Ou4tD85ITovXepjwGFQMAUE+Lb0udKtjUFxwcrMGDB7epILSce6bi3AIZBpP5AQAgtfFpqVWrVmndunXu1xkZGUpKStKvfvUrHT9OL4KvjOoTqSCrRUeKK3WgoNzscgAA8AttCjd33XWXioqKJEmbNm3SHXfcoUsvvVR79uxRenq6VwtE00KCbRoZHyGJR8IBAKjTpnCzZ88ejRw5UpL0+uuv67LLLtPChQuVkZGh999/36sFonnMdwMAgKc2hRu73a6ysjJJ0kcffaSLLrpIktSjRw93jw58wz1TcS63AwEAkNoYbiZNmqT09HQ99NBD2rBhg6ZOnSpJ2rFjh/r27duqc2VkZGjAgAEKCQnR+PHjtWHDhmb3Lygo0KxZs9S7d285HA6dfvrpeu+999pyGQGhblDxlgNFqqxxmlsMAAB+oE3h5qmnnlJQUJBee+01LV26VH369JEkvf/++7r44otbfJ6VK1cqPT1dCxYsUFZWlhITEzVlyhQdPny40f2rqqp04YUXau/evXrttde0fft2LV++3P35XVG/HmHq0c2uKqdL3x2k1wwAAIth4jPE48eP11lnnaWnnnpKUu3SDgkJCbrlllt07733Nth/2bJleuyxx7Rt27ZGJxFsTGVlpSorK92vi4qKlJCQoMLCQkVERHjnQkx2/Ytf6aOthzX/spH6zaSBZpcDAIDXFRUVKTIyskW/v9vUc5OVlaVNmza5X//rX//SFVdcofvuu09VVVUtOkdVVZUyMzOVmpp6shirVampqVq/fn2jx7z99tuaMGGCZs2apdjYWI0aNUoLFy6U09n07ZhFixYpMjLSvQXi2lcnx90UmFsIAAB+oE3h5qabbtKOHTskSbt379ZVV12lsLAwvfrqq7r77rtbdI6jR4/K6XQqNjbWoz02NlZ5eXmNHrN792699tprcjqdeu+99/TAAw/o8ccf18MPP9zk58ydO1eFhYXuLTc3t4VX2XmcfGKKQcUAALQp3OzYsUNJSUmSpFdffVU/+clP9PLLL+uFF17Q66+/7s36PLhcLvXq1UvPPPOMxo4dq2nTpun+++/XsmXLmjzG4XAoIiLCYws0YxKiZLFI+4+X63BxhdnlAABgqjaFG8Mw5HK5JNU+Cn7ppZdKkhISEnT06NEWnSMmJkY2m035+fke7fn5+YqLi2v0mN69e+v000+XzWZzt40YMUJ5eXktvh0WiLo7gjQsNlySlM18NwCALq5N4SYlJUUPP/yw/vrXv2rt2rXuR8H37NnT4DZTU+x2u8aOHas1a9a421wul9asWaMJEyY0esw555yjnTt3uoOVVNuL1Lt3b9nt9rZcSsCov84UAABdWZvCzeLFi5WVlaXZs2fr/vvv15AhQyRJr732miZOnNji86Snp2v58uV68cUXtXXrVs2cOVOlpaWaMWOGJGn69OmaO3eue/+ZM2fq2LFjmjNnjnbs2KF3331XCxcu1KxZs9pyGQElOeHEoGLG3QAAurigthw0ZswYj6el6jz22GMet4xOZdq0aTpy5Ijmz5+vvLw8JSUladWqVe7en5ycHFmtJ/NXQkKCPvjgA91+++0aM2aM+vTpozlz5uiee+5py2UElLqem2/3F6rG6VKQrU25FQCATq9d89xkZmZq69atkqSRI0fqzDPP9FphHaU1z8l3Ji6XocQHP1RxZY3eu/Vc94KaAAAEgtb8/m5Tz83hw4c1bdo0rV27VlFRUZJql0U4//zz9corr6hnz55tOS3awWq1KKlflD7//qg25h4n3AAAuqw23bu45ZZbVFJSoi1btujYsWM6duyYNm/erKKiIt16663erhEtxArhAAC0sedm1apV+uijjzRixAh328iRI5WRkeFeIRy+VzdTcRaDigEAXVibem5cLlejazsFBwd7PKYN30o60XOz+0ipCsq67rw/AICurU3h5oILLtCcOXN08OBBd9uBAwd0++23a/LkyV4rDq0T3c2ugTHdJEnZzHcDAOii2hRunnrqKRUVFWnAgAEaPHiwBg8erIEDB6qoqEhLlizxdo1oBcbdAAC6ujaNuUlISFBWVpY++ugjbdu2TVLtMgj1V/iGOZL7RemNjQeYqRgA0GW1KdxIksVi0YUXXqgLL7zQ3bZt2zb97Gc/c68YDt+rG1ScnXNcLpchq9VickUAAPiWV6exrays1K5du7x5SrTSsLhwhQRbVVRRo91HS80uBwAAn2OO/gATbLNqTJ8oSawzBQDomgg3AYgVwgEAXRnhJgC5ww1PTAEAuqBWDSiOjo6WxdL0ANWampp2F4T2qxtUvD2vSKWVNermaPO4cQAAOp1W/dZbvHhxB5UBb4qNCFF8ZIgOFlbo2/2FmjD4NLNLAgDAZ1oVbtLS0jqqDnhZcr9oHdx0SBtzjxNuAABdSovH3BiG0ZF1wMsYdwMA6KpaHG7OOOMMvfLKK6qqan5Bxu+//14zZ87Uo48+2u7i0Hb1ww3BFADQlbT4ttSTTz6pe+65R7/73e904YUXKiUlRfHx8QoJCdHx48f13Xffad26ddqyZYtmz56tmTNndmTdOIUz4iMVbLPoaEml9h8vV0KPMLNLAgDAJ1ocbiZPnqyvv/5a69at08qVK/X3v/9d+/btU3l5uWJiYpScnKzp06frmmuuUXR0dEfWjBYICbZpZO8IfbO/UBtzCwg3AIAuo9XPCE+aNEmTJk3qiFrgZcn9omvDTc5x/Swx3uxyAADwCSbxC2AMKgYAdEWEmwCWnFB7e/C7g0WqrHGaXA0AAL5BuAlgCT1CdVo3u6qcLm05WGR2OQAA+AThJoBZLBb3UgzcmgIAdBWEmwB3ctzNcXMLAQDAR9q9omJFRUWDif0iIiLae1p4CYOKAQBdTZt6bsrKyjR79mz16tVL3bp1U3R0tMcG/zGmb5SsFulAQbkOF1WYXQ4AAB2uTeHmrrvu0scff6ylS5fK4XDo2Wef1YMPPqj4+Hi99NJL3q4R7dDdEaTTY8MlSRtzC8wtBgAAH2hTuPn3v/+tp59+WldeeaWCgoJ07rnnat68eVq4cKH+/ve/e7tGtBODigEAXUmbws2xY8c0aNAgSbXja44dOyapdvbizz77zHvVwSsYVAwA6EraFG4GDRqkPXv2SJKGDx+uf/7zn5Jqe3SioqK8Vhy848wT4ebb/YWqcbrMLQYAgA7WpnAzY8YMffPNN5Kke++9VxkZGQoJCdHtt9+uu+66y6sFov0GxXRXeEiQyqud2p5fbHY5AAB0qDY9Cn777be7v09NTdW2bduUmZmpIUOGaMyYMV4rDt5htVqUlBClz78/qo05BTojPtLskgAA6DBemcSvf//++n//7/8RbPwYg4oBAF1Fi3tulixZ0uKT3nrrrW0qBh3HPag4l0HFAIDA1uJw86c//cnj9ZEjR1RWVuYeQFxQUKCwsDD16tWLcOOHkvpGSZJ2HylVQVmVosLs5hYEAEAHafFtqT179ri3Rx55RElJSdq6dauOHTumY8eOaevWrTrzzDP10EMPdWS9aKPobnYNiukmScpmMj8AQABr05ibBx54QE8++aSGDRvmbhs2bJj+9Kc/ad68eV4rDt6VxDpTAIAuoE3h5tChQ6qpqWnQ7nQ6lZ+f3+6i0DHqBhVnMZkfACCAtSncTJ48WTfddJOysrLcbZmZmZo5c6ZSU1O9Vhy8KzkhSlLtbSmXyzC3GAAAOkibws3zzz+vuLg4paSkyOFwyOFwaNy4cYqNjdWzzz7r7RrhJcPjwhUSbFVxRY12Hy0xuxwAADpEqyfxMwxD5eXlev3117V//35t3bpVUu0yDKeffrrXC4T3BNmsGtM3Shv2HFNWToGG9Ao3uyQAALyuTeFmyJAh2rJli4YOHaqhQ4d2RF3oIMn9asPNxpwC/TIlwexyAADwulbflrJarRo6dKh++OGHjqgHHSw5oW6mYgYVAwACU5vG3Dz66KO66667tHnzZm/Xgw5WN1PxjvxilVQ2fOINAIDOrk0LZ06fPl1lZWVKTEyU3W5XaGiox/vHjh3zSnHwvtiIEPWJCtWBgnJ9u79AEwfHmF0SAABe1aZws3jxYi+XAV9K6helAwXl2phDuAEABJ42hZu0tDRv1wEfSk6I0rvfHmKmYgBAQGrTmBtJ2rVrl+bNm6err75ahw8fliS9//772rJli9eKQ8eom6k4O/e4DIPJ/AAAgaVN4Wbt2rUaPXq0/u///k9vvPGGSkpqJ4T75ptvtGDBAq8WCO87Iz5CwTaLjpZUaf/xcrPLAQDAq9oUbu699149/PDDWr16tex2u7v9ggsu0Jdffum14tAxQoJtGhkfKYl1pgAAgadN4WbTpk36r//6rwbtvXr10tGjR9tdFDpe3TpTjLsBAASaNoWbqKgoHTp0qEH7xo0b1adPn3YXhY5XN9/NxtwCU+sAAMDb2hRurrrqKt1zzz3Ky8uTxWKRy+XSf/7zH915552aPn26t2tEBzjzxKDi7w4WqqLaaXI1AAB4T5vCzcKFCzV8+HAlJCSopKREI0eO1E9+8hNNnDhR8+bN83aN6AB9o0MV092uaqehLQeLzC4HAACvaVO4sdvtWr58uXbv3q133nlHf/vb37Rt2zb99a9/lc1m83aN6AAWi0VJrDMFAAhArZrEz+Vy6bHHHtPbb7+tqqoqTZ48WQsWLGiw/AI6hzP7R+mjrfmMuwEABJRW9dw88sgjuu+++9S9e3f16dNHf/7znzVr1qx2F5GRkaEBAwYoJCRE48eP14YNG1p03CuvvCKLxaIrrrii3TV0RXUrhGfzxBQAIIC0Kty89NJLevrpp/XBBx/orbfe0r///W/9/e9/l8vlanMBK1euVHp6uhYsWKCsrCwlJiZqypQp7lmPm7J3717deeedOvfcc9v82V3dmL6RslqkAwXlyi+qMLscAAC8olXhJicnR5deeqn7dWpqqiwWiw4ePNjmAp544gndcMMNmjFjhkaOHKlly5YpLCxMzz//fJPHOJ1OXXPNNXrwwQc1aNCgZs9fWVmpoqIijw21ujmCNCwuQhLz3QAAAkerwk1NTY1CQkI82oKDg1VdXd2mD6+qqlJmZqZSU1NPFmS1KjU1VevXr2/yuD/84Q/q1auXfvvb357yMxYtWqTIyEj3lpCQ0KZaA9XJ+W4YVAwACAytGlBsGIauu+46ORwOd1tFRYVuvvlmdevWzd32xhtvtOh8R48eldPpVGxsrEd7bGystm3b1ugx69at03PPPafs7OwWfcbcuXOVnp7ufl1UVETAqSc5IUov/18OPTcAgIDRqnCTlpbWoO3Xv/6114o5leLiYl177bVavny5YmJiWnSMw+HwCGPwVLdC+Lf7C1TjdCnI1uaF4gEA8AutCjcrVqzw6ofHxMTIZrMpPz/foz0/P19xcXEN9t+1a5f27t2ryy+/3N1WN5g5KChI27dv1+DBg71aY6AbFNNNESFBKqqo0ba8Yo3qE2l2SQAAtIup/0y32+0aO3as1qxZ425zuVxas2aNJkyY0GD/4cOHa9OmTcrOznZvP/vZz3T++ecrOzub201tYLValHSi94b5bgAAgaBVPTcdIT09XWlpaUpJSdG4ceO0ePFilZaWasaMGZKk6dOnq0+fPlq0aJFCQkI0atQoj+OjoqIkqUE7Wi45IUqf7TiijTnHde3Z/c0uBwCAdjE93EybNk1HjhzR/PnzlZeXp6SkJK1atco9yDgnJ0dWK+NAOlLdE1NM5gcACAQWwzAMs4vwpaKiIkVGRqqwsFARERFml+MXCsqqlPSH1ZKkjQ9cqOhudpMrAgDAU2t+f9MlAkWF2TWoZ+2j/Nn7C8wtBgCAdiLcQNLJdaaY7wYA0NkRbiCp3kzFOcxUDADo3Ag3kFRvUHFugVyuLjUMCwAQYAg3kCQNiw1XaLBNxRU12n20xOxyAABoM8INJElBNqvG9K2dnThrX4G5xQAA0A6EG7glu2cqZtwNAKDzItzA7eSg4gJT6wAAoD0IN3BLToiSJG3PL1ZJZY25xQAA0EaEG7j1ighRn6hQGYb0LYtoAgA6KcINPLhvTRFuAACdFOEGHtyDipnMDwDQSRFu4KH+oOIutqYqACBAEG7g4Yz4CNltVv1QWqXcY+VmlwMAQKsRbuDBEWTTyPjapeSZ7wYA0BkRbtAA890AADozwg0aYFAxAKAzI9yggbrJ/LYcLFJFtdPcYgAAaCXCDRroGx2qmO4O1bgMbTlYaHY5AAC0CuEGDVgsFsbdAAA6LcINGkW4AQB0VoQbNOpMBhUDADopwg0aNaZvpKwW6WBhhfIKK8wuBwCAFiPcoFFh9iANj6udzC+byfwAAJ0I4QZNYtwNAKAzItygSScn8yswtxAAAFqBcIMm1fXcfHugQNVOl7nFAADQQoQbNGngad0UGRqsimqXtucVm10OAAAtQrhBk6xWi5JOLMXAI+EAgM6CcINmMagYANDZEG7QLPeg4twCcwsBAKCFCDdoVlLfKEnSnqOlOl5aZW4xAAC0AOEGzYoMC9bgnt0kSdn03gAAOgHCDU4pmXWmAACdCOEGp+QeVEzPDQCgEyDc4JSSE2p7brJzCuRyGSZXAwBA8wg3OKXTY7srzG5TcWWNdh0pMbscAACaRbjBKQXZrBrTN1IS890AAPwf4QYtcnK+GwYVAwD8G+EGLZLsXoahwNQ6AAA4FcINWiTpxBNT2/OLVVxRbW4xAAA0g3CDFukVHqK+0aEyDOnb/YVmlwMAQJMIN2gxJvMDAHQGhBu0GONuAACdAeEGLVZ/pmLDYDI/AIB/ItygxUbGR8hus+pYaZVyjpWZXQ4AAI0i3KDFHEE2ndEnQhK3pgAA/otwg1apW2eKQcUAAH9FuEGrsEI4AMDfEW7QKnXh5ruDRaqodppbDAAAjSDcoFX6RIWqZ7hDNS5Dmw8wmR8AwP8QbtAqFouF+W4AAH6NcINWY4VwAIA/I9yg1dyDium5AQD4IcINWm1M30jZrBYdKqzQocJys8sBAMAD4QatFmYP0vC4cElSNr03AAA/Q7hBmzDfDQDAX/lFuMnIyNCAAQMUEhKi8ePHa8OGDU3uu3z5cp177rmKjo5WdHS0UlNTm90fHYOZigEA/sr0cLNy5Uqlp6drwYIFysrKUmJioqZMmaLDhw83uv+nn36qq6++Wp988onWr1+vhIQEXXTRRTpw4ICPK+/a6npuvt1fqGqny9xiAACox2IYhmFmAePHj9dZZ52lp556SpLkcrmUkJCgW265Rffee+8pj3c6nYqOjtZTTz2l6dOnn3L/oqIiRUZGqrCwUBEREe2uv6syDENJf1itwvJq/Xv2JI3uG2l2SQCAANaa39+m9txUVVUpMzNTqamp7jar1arU1FStX7++RecoKytTdXW1evTo0ej7lZWVKioq8tjQfhaLpd64G25NAQD8h6nh5ujRo3I6nYqNjfVoj42NVV5eXovOcc899yg+Pt4jINW3aNEiRUZGureEhIR2141aJ8fdFJhbCAAA9Zg+5qY9Hn30Ub3yyit68803FRIS0ug+c+fOVWFhoXvLzc31cZWB6+RkfvTcAAD8R5CZHx4TEyObzab8/HyP9vz8fMXFxTV77P/+7//q0Ucf1UcffaQxY8Y0uZ/D4ZDD4fBKvfCUeGKNqb0/lOlYaZV6dLObWxAAADK558Zut2vs2LFas2aNu83lcmnNmjWaMGFCk8f9z//8jx566CGtWrVKKSkpvigVjYgMDdaQXt0lSdmMuwEA+AnTb0ulp6dr+fLlevHFF7V161bNnDlTpaWlmjFjhiRp+vTpmjt3rnv/P/7xj3rggQf0/PPPa8CAAcrLy1NeXp5KSkrMuoQujRXCAQD+xtTbUpI0bdo0HTlyRPPnz1deXp6SkpK0atUq9yDjnJwcWa0nM9jSpUtVVVWl//7v//Y4z4IFC/T73//el6VDtSuEv5q5n3ADAPAbps9z42vMc+NdWw8V6ZI/f67ujiB9s+Ai2awWs0sCAASgTjPPDTq/02PDFWa3qaSyRruOcGsQAGA+wg3axWa1KLFvlCQeCQcA+AfCDdrt5Hw3BabWAQCARLiBFyT3Y6ZiAID/INyg3ZJOPA6+43CxiiuqzS0GANDlEW7Qbj3DHUroESrDkL7dX2h2OQCALo5wA684uYgmg4oBAOYi3MArGFQMAPAXhBt4hXtQcW6Buti8kAAAP0O4gVeM7B0he5BVx0qr9O6mQwQcAIBpCDfwCnuQVT8ZGiNJmv3yRl3+1Dqt2pwnl4uQAwDwLcINvObxXyTppvMGKcxu0+YDRbr5b5m6dMnneufbg3IScgAAPsLCmfC6Y6VVen7dHr34xV4VV9ZIkgb37KZbLhiqy8b0VpCNTA0AaJ3W/P4m3KDDFJZVa8UXe/T8uj0qqqgNOQNOC9Os84foiuQ+CibkAABaiHDTDMKN7xVXVOul9fv07Oe7dbysdgbjvtGh+t1Ph+i/x/aVPYiQAwBoHuGmGYQb85RW1ujv/7dPz3y2W0dLqiRJ8ZEhuvmng/XLlASFBNtMrhAA4K8IN80g3JivvMqpf2zI0bK1u3S4uFKS1CvcoZvOG6xfjeunUDshBwDgiXDTDMKN/6iodurVr3O19NNdOlhYIUmK6W7XDecO0q/P7q9ujiCTKwQA+AvCTTMIN/6nqsal17P26+lPdyr3WLkkKTosWL+dNFDTJw5QREiwyRUCAMxGuGkG4cZ/VTtd+lf2QWV8slN7jpZKkiJCgjTjnIH6zTkDFRlGyAGAropw0wzCjf+rcbr07qZDevLjndp5uESS1N0RpLSJ/fXbSYPUo5vd5AoBAL5GuGkG4abzcLkMvb85T09+/L225RVLksLsNl17dn9df+4g9Qx3mFwhAMBXCDfNINx0Pi6XodVb8/Xkx99r84EiSVJIsFW/GtdfN503SLERISZXCADoaISbZhBuOi/DMPTJ9sNasmansnMLJNUu2DktJUE3/3Sw+kSFmlsgAKDDEG6aQbjp/AzD0LqdR7Vkzff6au9xSVKwzaL/HttXv/vpECX0CDO5QgCAtxFumkG4CRyGYejL3ce0ZM33Wr/7B0mSzWrRfyX30azzh2hgTDeTKwQAeAvhphmEm8D09d5jWvLxTn2244gkyWqRLk+M1+zzh2hobLjJ1QEA2otw0wzCTWDLzi3Qk2u+15pthyVJFot06ajemn3BEI3ozZ83AHRWhJtmEG66hs0HCvXkx9/rgy357raLRsbq1slDNapPpImVAQDagnDTDMJN17Itr0hPfrxT7206pLq/6RcM76VbLhii5H7R5hYHAGgxwk0zCDdd087Dxcr4ZJf+lX1ArhN/488dGqNbJw/VWQN6mFscAOCUCDfNINx0bXuOlurpT3bqjY0H5DyRcs4e1EO3Th6qCYNOk8ViMblCAEBjCDfNINxAknKPlenpT3fptcxcVTtr/xNI6R+tWycP1blDYwg5AOBnCDfNINygvoMF5Vq2dpde+SpXVTUuSVJiQpRuvWCILhjei5ADAH6CcNMMwg0ak19Uob+s3a2XN+xTRXVtyDkjPkK3XDBUF42MldVKyAEAMxFumkG4QXOOFFfq2XW79df1+1RW5ZQkDYsN1y2Th+iSUb1lI+QAgCkIN80g3KAljpVW6fl1e/TCF3tVUlkjSRrcs5tuuWCoLhvTW0E2q8kVAkDXQrhpBuEGrVFYVq0VX+zR8+v2qKiiNuQMOC1Mvzt/iP4ruY+CCTkA4BOEm2YQbtAWxRXVemn9Pj37+W4dL6uWJPWNDtXvfjpEV47tI0eQzeQKASCwEW6aQbhBe5RW1ujv/7dPz3y2W0dLqiRJvSNDNPOng/XLlASFBBNyAKAjEG6aQbiBN5RXOfWPDTlatnaXDhdXSpJ6hTt0408G6exBpykqLFhRYXZ1s9t4nBwAvIBw0wzCDbypotqpV7/O1dJPd+lgYUWD94OsFkWGBisyLFiRocGKCq0NPZGhJ16H1f9q92hjPA8AnES4aQbhBh2hqsal17P26x8bcpRXWKGC8mr3pIBt1c1uaxCEosKCFREarKhQ+8lgVD880VsEIEARbppBuIGvVFQ7VVBWrYLyKhWWVaugvFqFZdUqLK9tKzjxfWF5tfv7grIq91NZbVW/tygq9GTo+XFIqn1tr/c9vUUA/Fdrfn8H+agmoMsJCbYpLtKmuMiQVh3ndBkqrqg+EYxOhp7CE+GooF4YKiyvcoejut6iGpehH0qr9ENpVatr7u4IOuUts7rAFBl2MjTRWwTAnxBuAD9js1oUFWZXVJi91ce2t7eopLJGJZU1OlBQ3qrPDbJa3LfMIkKC1d0RpG4Om7o5gk58f+Kr3bPt5Pc2dxu9RwDai3ADBBBf9RadDEbVqnLW9hYdLalyPx7fHvYg68lwZP9ROHI0Fo489/PY1x7EumBAF0S4AdDm3iLDMFRR7fLoGSquqFHpiR6guq9135dWOj3aS6tOttUNwK6qcelYTZWOlXrn2sI8eosaBqHwkCB1s3v2Hp1837PNEWTl9hvQCRBuALSZxWJRqN2mUHvre4t+rNrpqheKnPUCUb1wVPWjcNTEviWVNXKdeFSirMqpsiqnjpyYj6g9bFaLutltjfcSnfg+zB4km1WyWiyyWCyyWiSLar9arRZZ6r+21L6u/9Vq0Ynj6trqvZZkbeLcda8bO2fDz2ji3PX3sbb93EE2ixxBVtlthEGYg3ADwC8E26xtHmv0Y3U9Sg2CUFWNSiqdDUJTg7Yqz9BUt0K802WoqKKm3U+0dSX2IKscQVY5gmwnvlpr24JPvq7/vnv/E+/bbVY5gn/8/oljT7Tb658n2FbvGAKWGQzDkMuo/ceAWQg3AAJO/R6lnuGOdp/P6TJUVtVEj1K9wFRSURuEXIbh/h+868RXyZDLdfK1IUNGvfcNo/7rura6XxR1x9R77ao9h8uQx2cZjbz2+CrP1yeP8XztqvfZhiSX60f1/uiz677+WFWNS1U1LhXLvEDY2oDlCK4LVT/a3+P9pgNWsM0qp8uQ0zBqv9bbaly1P9Ma54mvLkOuE+3u/QxDTpdLTpd+9LXe8fWOcx9vGHI6G//cuvM2dlxdPc0d1/R1uOQypBqXSy7Xia+GlNI/Wq/NnGjanznhBgBOwWa1KDwkWOEhwWaX4vfqfmFW1jhVWeOq3aqdqnK6VFl94nWNU1U1J7+va6+qe13zo9f1jnOfs4nz1h1Xnz8ErK7GafIUeoQbAIDXWK0W2a0W2YOsCjepBsMwakNPTW3wqQ1AzYemH4etk8c3ctyJ81aeOK/HsTUuVTtdslksslnrNqtsVinIaq3XZvnRPp7tQbYT45esFlmtnl+bO85mO3F8I8fVna9+TfW/Ntynic848X2Dc9tOvh8cZO6UDoQbAEBAsVgsJ24h2aT2jXNHJ8VsWQAAIKAQbgAAQEAh3AAAgIDiF+EmIyNDAwYMUEhIiMaPH68NGzY0u/+rr76q4cOHKyQkRKNHj9Z7773no0oBAIC/Mz3crFy5Uunp6VqwYIGysrKUmJioKVOm6PDhw43u/8UXX+jqq6/Wb3/7W23cuFFXXHGFrrjiCm3evNnHlQMAAH9kMQxzH0YfP368zjrrLD311FOSJJfLpYSEBN1yyy269957G+w/bdo0lZaW6p133nG3nX322UpKStKyZctO+XlFRUWKjIxUYWGhIiIivHchAACgw7Tm97epPTdVVVXKzMxUamqqu81qtSo1NVXr169v9Jj169d77C9JU6ZMaXL/yspKFRUVeWwAACBwmRpujh49KqfTqdjYWI/22NhY5eXlNXpMXl5eq/ZftGiRIiMj3VtCQoJ3igcAAH7J9DE3HW3u3LkqLCx0b7m5uWaXBAAAOpCpMxTHxMTIZrMpPz/foz0/P19xcXGNHhMXF9eq/R0OhxyO9i+cBwAAOgdTe27sdrvGjh2rNWvWuNtcLpfWrFmjCRMmNHrMhAkTPPaXpNWrVze5PwAA6FpMX1sqPT1daWlpSklJ0bhx47R48WKVlpZqxowZkqTp06erT58+WrRokSRpzpw5Ou+88/T4449r6tSpeuWVV/T111/rmWeeMfMyAACAnzA93EybNk1HjhzR/PnzlZeXp6SkJK1atco9aDgnJ0dW68kOpokTJ+rll1/WvHnzdN9992no0KF66623NGrUKLMuAQAA+BHT57nxNea5AQCg82nN72/Te258rS7LMd8NAACdR93v7Zb0yXS5cFNcXCxJzHcDAEAnVFxcrMjIyGb36XK3pVwulw4ePKjw8HBZLBavnruoqEgJCQnKzc3tkre8uvr1S/wMuP6uff0SP4Oufv1Sx/0MDMNQcXGx4uPjPcbiNqbL9dxYrVb17du3Qz8jIiKiy/6llrh+iZ8B19+1r1/iZ9DVr1/qmJ/BqXps6gT8DMUAAKBrIdwAAICAQrjxIofDoQULFnTZ5R66+vVL/Ay4/q59/RI/g65+/ZJ//Ay63IBiAAAQ2Oi5AQAAAYVwAwAAAgrhBgAABBTCDQAACCiEGy/JyMjQgAEDFBISovHjx2vDhg1ml+Qzn332mS6//HLFx8fLYrHorbfeMrskn1q0aJHOOusshYeHq1evXrriiiu0fft2s8vyqaVLl2rMmDHuSbsmTJig999/3+yyTPPoo4/KYrHotttuM7sUn/n9738vi8XisQ0fPtzssnzqwIED+vWvf63TTjtNoaGhGj16tL7++muzy/KJAQMGNPjzt1gsmjVrlin1EG68YOXKlUpPT9eCBQuUlZWlxMRETZkyRYcPHza7NJ8oLS1VYmKiMjIyzC7FFGvXrtWsWbP05ZdfavXq1aqurtZFF12k0tJSs0vzmb59++rRRx9VZmamvv76a11wwQX6+c9/ri1btphdms999dVX+stf/qIxY8aYXYrPnXHGGTp06JB7W7dundkl+czx48d1zjnnKDg4WO+//76+++47Pf7444qOjja7NJ/46quvPP7sV69eLUn6xS9+YU5BBtpt3LhxxqxZs9yvnU6nER8fbyxatMjEqswhyXjzzTfNLsNUhw8fNiQZa9euNbsUU0VHRxvPPvus2WX4VHFxsTF06FBj9erVxnnnnWfMmTPH7JJ8ZsGCBUZiYqLZZZjmnnvuMSZNmmR2GX5jzpw5xuDBgw2Xy2XK59Nz005VVVXKzMxUamqqu81qtSo1NVXr1683sTKYpbCwUJLUo0cPkysxh9Pp1CuvvKLS0lJNmDDB7HJ8atasWZo6darH/w+6ku+//17x8fEaNGiQrrnmGuXk5Jhdks+8/fbbSklJ0S9+8Qv16tVLycnJWr58udllmaKqqkp/+9vf9Jvf/MbrC1S3FOGmnY4ePSqn06nY2FiP9tjYWOXl5ZlUFczicrl022236ZxzztGoUaPMLsenNm3apO7du8vhcOjmm2/Wm2++qZEjR5pdls+88sorysrK0qJFi8wuxRTjx4/XCy+8oFWrVmnp0qXas2ePzj33XBUXF5tdmk/s3r1bS5cu1dChQ/XBBx9o5syZuvXWW/Xiiy+aXZrPvfXWWyooKNB1111nWg1dblVwoCPNmjVLmzdv7lJjDeoMGzZM2dnZKiws1Guvvaa0tDStXbu2SwSc3NxczZkzR6tXr1ZISIjZ5ZjikksucX8/ZswYjR8/Xv3799c///lP/fa3vzWxMt9wuVxKSUnRwoULJUnJycnavHmzli1bprS0NJOr863nnntOl1xyieLj402rgZ6bdoqJiZHNZlN+fr5He35+vuLi4kyqCmaYPXu23nnnHX3yySfq27ev2eX4nN1u15AhQzR27FgtWrRIiYmJ+vOf/2x2WT6RmZmpw4cP68wzz1RQUJCCgoK0du1aLVmyREFBQXI6nWaX6HNRUVE6/fTTtXPnTrNL8YnevXs3CPIjRozoUrfmJGnfvn366KOPdP3115taB+Gmnex2u8aOHas1a9a421wul9asWdPlxht0VYZhaPbs2XrzzTf18ccfa+DAgWaX5BdcLpcqKyvNLsMnJk+erE2bNik7O9u9paSk6JprrlF2drZsNpvZJfpcSUmJdu3apd69e5tdik+cc845DaaA2LFjh/r3729SReZYsWKFevXqpalTp5paB7elvCA9PV1paWlKSUnRuHHjtHjxYpWWlmrGjBlml+YTJSUlHv8627Nnj7Kzs9WjRw/169fPxMp8Y9asWXr55Zf1r3/9S+Hh4e6xVpGRkQoNDTW5Ot+YO3euLrnkEvXr10/FxcV6+eWX9emnn+qDDz4wuzSfCA8PbzDGqlu3bjrttNO6zNirO++8U5dffrn69++vgwcPasGCBbLZbLr66qvNLs0nbr/9dk2cOFELFy7UL3/5S23YsEHPPPOMnnnmGbNL8xmXy6UVK1YoLS1NQUEmxwtTntEKQE8++aTRr18/w263G+PGjTO+/PJLs0vymU8++cSQ1GBLS0szuzSfaOzaJRkrVqwwuzSf+c1vfmP079/fsNvtRs+ePY3JkycbH374odllmaqrPQo+bdo0o3fv3obdbjf69OljTJs2zdi5c6fZZfnUv//9b2PUqFGGw+Ewhg8fbjzzzDNml+RTH3zwgSHJ2L59u9mlGBbDMAxzYhUAAID3MeYGAAAEFMINAAAIKIQbAAAQUAg3AAAgoBBuAABAQCHcAACAgEK4AQAAAYVwAwAAAgrhBkCT5syZoxtvvFEul8vsUgCgxQg3ABqVm5urYcOG6S9/+YusVv5XAaDzYPkFAF3G9u3bdd555+n7779XeHi42eV4uOqqq3TWWWfpjjvuMLsUoNPjn2MAPFx33XWyWCwNtosvvtjs0tpt7ty5uuWWW1oVbB555BFNnDhRYWFhioqKanSfnJwcTZ06VWFhYerVq5fuuusu1dTUeOzz6aef6swzz5TD4dCQIUP0wgsveLw/b948PfLIIyosLGztZQH4EcINgAYuvvhiHTp0yGP7xz/+YXZZ7ZKTk6N33nlH1113XauOq6qq0i9+8QvNnDmz0fedTqemTp2qqqoqffHFF3rxxRf1wgsvaP78+e599uzZo6lTp+r8889Xdna2brvtNl1//fX64IMP3PuMGjVKgwcP1t/+9rc2XR+AesxdlByAv0lLSzN+/vOfN7uPJOPpp582Lr74YiMkJMQYOHCg8eqrr3rs8+233xrnn3++ERISYvTo0cO44YYbjOLiYo99nnvuOWPkyJGG3W434uLijFmzZrnfe/zxx41Ro0YZYWFhRt++fY2ZM2d6HL93717jsssuM6KiooywsDBj5MiRxrvvvttkzY899piRkpLi0TZjxgxj9OjRRkVFhWEYhlFZWWkkJSUZ1157bYPjV6xYYURGRjZof++99wyr1Wrk5eW525YuXWpEREQYlZWVhmEYxt13322cccYZHsdNmzbNmDJlikfbgw8+aEyaNKnJawDQMvTcAGiTBx54QFdeeaW++eYbXXPNNbrqqqu0detWSVJpaammTJmi6OhoffXVV3r11Vf10Ucfafbs2e7jly5dqlmzZunGG2/Upk2b9Pbbb2vIkCHu961Wq5YsWaItW7boxRdf1Mcff6y7777b/f6sWbNUWVmpzz77TJs2bdIf//hHde/evcl6P//8c6WkpHi0LVmyRKWlpbr33nslSffff78KCgr01FNPtfjnsH79eo0ePVqxsbHutilTpqioqEhbtmxx75Oamupx3JQpU7R+/XqPtnHjxmnDhg2qrKxs8ecDaITZ6QqAf0lLSzNsNpvRrVs3j+2RRx5x7yPJuPnmmz2OGz9+vDFz5kzDMAzjmWeeMaKjo42SkhL3+++++65HD0d8fLxx//33t7iuV1991TjttNPcr0ePHm38/ve/b/HxiYmJxh/+8IcG7V988YURHBxsPPDAA0ZQUJDx+eefN3p8Uz03N9xwg3HRRRd5tJWWlhqSjPfee88wDMMYOnSosXDhQo993n33XUOSUVZW5m775ptvDEnG3r17W3xdABoKMjdaAfBH559/vpYuXerR1qNHD4/XEyZMaPA6OztbkrR161YlJiaqW7du7vfPOeccuVwubd++XRaLRQcPHtTkyZObrOGjjz7SokWLtG3bNhUVFammpkYVFRUqKytTWFiYbr31Vs2cOVMffvihUlNTdeWVV2rMmDFNnq+8vFwhISEN2idMmKA777xTDz30kO655x5NmjSpyXN0tNDQUElSWVmZaTUAgYDbUgAa6Natm4YMGeKx/TjctEfdL/Gm7N27V5dddpnGjBmj119/XZmZmcrIyJBUO8BXkq6//nrt3r1b1157rTZt2qSUlBQ9+eSTTZ4zJiZGx48fb9Ducrn0n//8RzabTTt37mz1tcTFxSk/P9+jre51XFxcs/tERER4/CyOHTsmSerZs2er6wBwEuEGQJt8+eWXDV6PGDFCkjRixAh98803Ki0tdb//n//8R1arVcOGDVN4eLgGDBigNWvWNHruzMxMuVwuPf744zr77LN1+umn6+DBgw32S0hI0M0336w33nhDd9xxh5YvX95kvcnJyfruu+8atD/22GPatm2b1q5dq1WrVmnFihUtuv46EyZM0KZNm3T48GF32+rVqxUREaGRI0e69/nxta5evbpB79fmzZvVt29fxcTEtKoGAD9i9n0xAP4lLS3NuPjii41Dhw55bEeOHHHvI8mIiYkxnnvuOWP79u3G/PnzDavVamzZssUwjNoxJ7179zauvPJKY9OmTcbHH39sDBo0yEhLS3Of44UXXjBCQkKMP//5z8aOHTuMzMxMY8mSJYZhGEZ2drYhyVi8eLGxa9cu46WXXjL69OljSDKOHz9uGIZhzJkzx1i1apWxe/duIzMz0xg/frzxy1/+ssnrevvtt41evXoZNTU17rasrCzDbrcbb7/9tmEYhvGXv/zFCA8PN3bt2uXeZ9++fcbGjRuNBx980OjevbuxceNGY+PGje4nt2pqaoxRo0YZF110kZGdnW2sWrXK6NmzpzF37lz3OXbv3m2EhYUZd911l7F161YjIyPDsNlsxqpVqxr87H/zm9+05o8LQCMINwA8pKWlGZIabMOGDXPvI8nIyMgwLrzwQsPhcBgDBgwwVq5c6XGeljwKvmzZMmPYsGFGcHCw0bt3b+OWW25xv/fEE08YvXv3NkJDQ40pU6YYL730kke4mT17tjF48GDD4XAYPXv2NK699lrj6NGjTV5XdXW1ER8f7w4U5eXlxsiRI40bb7zRY7+f/exnxsSJE90hqKmfxyeffOI+Zu/evcYll1xihIaGGjExMcYdd9xhVFdXe5z3k08+MZKSkgy73W4MGjTIWLFihcf75eXlRmRkpLF+/fomrwFAy7D8AoBWs1gsevPNN3XFFVeYXUqrZGRk6O233/aYPM9fLF26VG+++aY+/PBDs0sBOj2elgLQZdx0000qKChQcXGx360tFRwc3OyAaAAtR88NgFbrrD03ALoGem4AtBr/JgLgz3gUHAAABBTCDQAACCiEGwAAEFAINwAAIKAQbgAAQEAh3AAAgIBCuAEAAAGFcAMAAALK/weF1ZAEDKy0QQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Avaliando o modelo\n",
        "\n",
        "Após o término do treinamento, mudamos os modelos para o modo de avaliação (`.eval()`) e chamamos `evaluateRandomly` para ver alguns resultados.\n",
        "\n",
        "-----"
      ],
      "metadata": {
        "id": "-YahdILSYntS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Avalia resultados aleatórios\n",
        "encoder.eval()\n",
        "decoder.eval()\n",
        "evaluateRandomly(encoder, decoder, pairs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2kYNHArDRWZ-",
        "outputId": "a7adea7c-21bc-4b1b-bd2f-912228fabdf2"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> o tom pediu um conselho a mary .\n",
            "= tom asked mary for advice .\n",
            "< tom asked mary for advice . <EOS>\n",
            "\n",
            "> isso e bom ?\n",
            "= does that feel good ?\n",
            "< does that feel good ? <EOS>\n",
            "\n",
            "> ela perdeu o pouco dinheiro que tinha .\n",
            "= she lost what little money she had .\n",
            "< she lost what little money she had . <EOS>\n",
            "\n",
            "> quem o tom achou que iria ajuda lo ?\n",
            "= who did tom think would help him ?\n",
            "< who did tom think would help him ? <EOS>\n",
            "\n",
            "> eu sei que voce e feliz .\n",
            "= i know you re happy .\n",
            "< i know that you re happy . <EOS>\n",
            "\n",
            "> eu nao sei o endereco dela .\n",
            "= i don t know her address .\n",
            "< i don t know her address . <EOS>\n",
            "\n",
            "> tom disse a mary que era canadense .\n",
            "= tom told mary that he was canadian .\n",
            "< tom told mary that he was canadian . <EOS>\n",
            "\n",
            "> de maneira alguma !\n",
            "= no way !\n",
            "< no way ! <EOS>\n",
            "\n",
            "> acho que tom estava cansado .\n",
            "= i think tom was tired .\n",
            "< i think that tom was tired . <EOS>\n",
            "\n",
            "> eu nao acho que a mary seja bonita .\n",
            "= i don t think mary is beautiful .\n",
            "< i don t think mary is beautiful . <EOS>\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Métricas de Desempenho: Calculando o BLEU Score\n",
        "\n",
        "A métrica mais comum para tradução automática é o **BLEU (Bilingual Evaluation Understudy)**. De forma simples, o BLEU compara a tradução gerada pelo seu modelo com uma ou mais traduções humanas de referência. Ele gera uma pontuação de 0 a 1 (ou 0 a 100), onde valores mais altos indicam que a tradução do modelo é mais similar à tradução de referência.\n",
        "\n",
        "-----"
      ],
      "metadata": {
        "id": "5AFtKjD1YyKA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sacrebleu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--WbiKTebGsF",
        "outputId": "44cf22c1-c009-4f07-a450-c8081ee178c6"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.11/dist-packages (2.5.1)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (3.2.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (2024.11.6)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (2.0.2)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (0.4.6)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (5.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sacrebleu\n",
        "\n",
        "def calculate_bleu_with_sacrebleu(pairs, encoder, decoder, input_lang, output_lang):\n",
        "    \"\"\"\n",
        "    Calcula a pontuação BLEU usando a biblioteca externa sacrebleu.\n",
        "    \"\"\"\n",
        "    print(\"Calculando a pontuação BLEU com sacrebleu...\")\n",
        "\n",
        "    # sacrebleu espera listas de sentenças (strings), não de tokens\n",
        "    candidates = []\n",
        "    references = []\n",
        "\n",
        "    for pair in pairs:\n",
        "        source_sentence = pair[0]\n",
        "        # A referência já é uma string, que é o que precisamos\n",
        "        reference_sentence = pair[1]\n",
        "\n",
        "        # Gera a tradução (candidata) com o modelo\n",
        "        output_words, _ = evaluate(encoder, decoder, source_sentence, input_lang, output_lang)\n",
        "\n",
        "        if output_words[-1] == '<EOS>':\n",
        "            output_words = output_words[:-1]\n",
        "\n",
        "        # Junta os tokens da candidata em uma única string\n",
        "        candidate_sentence = ' '.join(output_words)\n",
        "\n",
        "        candidates.append(candidate_sentence)\n",
        "        references.append(reference_sentence)\n",
        "\n",
        "    # A API do sacrebleu espera a lista de referências dentro de outra lista,\n",
        "    # pois suporta múltiplas referências por sentença.\n",
        "    # A pontuação já vem na escala de 0 a 100.\n",
        "    bleu = sacrebleu.corpus_bleu(candidates, [references])\n",
        "\n",
        "    print(f\"Pontuação BLEU (sacrebleu): {bleu.score:.2f}\")\n",
        "\n",
        "    return bleu.score"
      ],
      "metadata": {
        "id": "j6bf133Ka1Pj"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bleu_value = calculate_bleu_with_sacrebleu(pairs, encoder, decoder, input_lang, output_lang)"
      ],
      "metadata": {
        "id": "ttP8PPGAa9r9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99ddffea-6003-4aea-de9e-76c2aec57a5c"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculando a pontuação BLEU com sacrebleu...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sacrebleu:That's 100 lines that end in a tokenized period ('.')\n",
            "WARNING:sacrebleu:It looks like you forgot to detokenize your test data, which may hurt your score.\n",
            "WARNING:sacrebleu:If you insist your data is detokenized, or don't care, you can suppress this message with the `force` parameter.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pontuação BLEU (sacrebleu): 83.18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Salva apenas os pesos (o dicionário de estado)\n",
        "torch.save(encoder.state_dict(), 'gru_encoder_pesos.pth')\n",
        "torch.save(decoder.state_dict(), 'gru_decoder_pesos.pth')\n",
        "\n",
        "print(\"Pesos do modelo GRU salvos com sucesso!\")\n",
        "\n",
        "# Salva o modelo completo\n",
        "torch.save(encoder, 'gru_encoder_completo.pth')\n",
        "torch.save(decoder, 'gru_decoder_completo.pth')\n",
        "\n",
        "print(\"Modelo GRU completo salvo com sucesso!\")"
      ],
      "metadata": {
        "id": "GwgsYD7ca-x2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "861637c6-0e9d-4913-a60a-72b94b0e5ba4"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pesos do modelo GRU salvos com sucesso!\n",
            "Modelo GRU completo salvo com sucesso!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "l_0U6wxTWByA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}